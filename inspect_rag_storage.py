"""
æŸ¥çœ‹RAGçŸ¥è¯†åº“å­˜å‚¨å†…å®¹
å±•ç¤ºå‘é‡æ•°æ®åº“ä¸­çš„æ‰€æœ‰æ–‡æ¡£å’Œå…ƒæ•°æ®
"""
import sys
import os
import asyncio

# æ·»åŠ é¡¹ç›®è·¯å¾„
sys.path.insert(0, os.path.join(os.path.dirname(__file__), 'src', 'backend'))

async def inspect_knowledge_base():
    """æ£€æŸ¥çŸ¥è¯†åº“å­˜å‚¨çš„è¯¦ç»†å†…å®¹"""
    print("=" * 70)
    print("RAG çŸ¥è¯†åº“å­˜å‚¨å†…å®¹æ£€æŸ¥")
    print("=" * 70)

    try:
        from app.services.rag_knowledge_service import RAGKnowledgeService
        from pathlib import Path

        # åˆ›å»ºRAGæœåŠ¡å®ä¾‹
        rag_service = RAGKnowledgeService()
        await rag_service.ensure_ready()

        # 1. æ˜¾ç¤ºå­˜å‚¨ä½ç½®
        print("\nğŸ“ å­˜å‚¨ä½ç½®ä¿¡æ¯ï¼š")
        print(f"   é¡¹ç›®æ ¹ç›®å½•: {rag_service.project_root}")
        print(f"   çŸ¥è¯†åº“ç›®å½•: {rag_service.knowledge_base_dir}")
        print(f"   å‘é‡æ•°æ®åº“ç›®å½•: {rag_service.vector_store_dir}")

        # 2. æ˜¾ç¤ºç›®å½•ç»“æ„å’Œæ–‡ä»¶å¤§å°
        print("\nğŸ“‚ å‘é‡æ•°æ®åº“ç›®å½•ç»“æ„ï¼š")
        vector_dir = Path(rag_service.vector_store_dir)

        if vector_dir.exists():
            total_size = 0
            for item in sorted(vector_dir.rglob("*")):
                if item.is_file():
                    size = item.stat().st_size
                    total_size += size
                    relative_path = item.relative_to(vector_dir)

                    if size < 1024:
                        size_str = f"{size} B"
                    elif size < 1024 * 1024:
                        size_str = f"{size / 1024:.1f} KB"
                    else:
                        size_str = f"{size / (1024 * 1024):.2f} MB"

                    print(f"   - {relative_path}: {size_str}")

            print(f"\n   æ€»å¤§å°: {total_size / (1024 * 1024):.2f} MB")
        else:
            print("   âš ï¸ å‘é‡æ•°æ®åº“ç›®å½•ä¸å­˜åœ¨")

        # 3. è·å–ç»Ÿè®¡ä¿¡æ¯
        print("\nğŸ“Š æ•°æ®åº“ç»Ÿè®¡ï¼š")
        stats = await rag_service.get_knowledge_stats()
        print(f"   æ–‡æ¡£ç‰‡æ®µæ€»æ•°: {stats.get('document_count', 0)}")
        print(f"   åµŒå…¥æ¨¡å‹: {stats.get('embedding_model', 'N/A')}")
        print(f"   å‘é‡ç»´åº¦: {stats.get('embedding_dimensions', 0)}")
        print(f"   æ•°æ®åº“çŠ¶æ€: {stats.get('status', 'unknown')}")

        # 4. è·å–å¹¶æ˜¾ç¤ºæ‰€æœ‰æ–‡æ¡£çš„å…ƒæ•°æ®
        print("\nğŸ“„ å­˜å‚¨çš„æ–‡æ¡£åˆ—è¡¨ï¼š")
        print("=" * 70)

        # ç›´æ¥è®¿é—®ChromaDB collectionè·å–æ‰€æœ‰æ–‡æ¡£
        if rag_service.vectorstore:
            collection = rag_service.vectorstore._collection

            # è·å–æ‰€æœ‰æ–‡æ¡£
            results = collection.get(
                include=['documents', 'metadatas']
            )

            documents = results.get('documents', [])
            metadatas = results.get('metadatas', [])
            ids = results.get('ids', [])

            # æŒ‰æ¥æºåˆ†ç»„ç»Ÿè®¡
            source_groups = {}
            for doc_id, doc, metadata in zip(ids, documents, metadatas):
                source = metadata.get('source', 'unknown')

                if source not in source_groups:
                    source_groups[source] = {
                        'count': 0,
                        'total_length': 0,
                        'metadata': metadata,
                        'preview': doc[:150] if doc else ''
                    }

                source_groups[source]['count'] += 1
                source_groups[source]['total_length'] += len(doc) if doc else 0

            # æ˜¾ç¤ºæ¯ä¸ªæ¥æº
            for i, (source, info) in enumerate(sorted(source_groups.items()), 1):
                print(f"\n{i}. æ¥æº: {source}")
                print(f"   æ–‡æ¡£ç‰‡æ®µæ•°: {info['count']}")
                print(f"   æ€»å­—ç¬¦æ•°: {info['total_length']:,}")

                # æ˜¾ç¤ºå…ƒæ•°æ®
                metadata = info['metadata']
                print("   å…ƒæ•°æ®:")
                for key, value in sorted(metadata.items()):
                    if key != 'source':
                        if isinstance(value, str) and len(value) > 50:
                            value = value[:50] + "..."
                        print(f"      - {key}: {value}")

                # æ˜¾ç¤ºå†…å®¹é¢„è§ˆ
                print(f"   å†…å®¹é¢„è§ˆ: {info['preview']}...")

            print("\n" + "=" * 70)
            print(f"âœ… å…± {len(source_groups)} ä¸ªä¸åŒæ¥æºçš„æ–‡æ¡£")
            print(f"âœ… æ€»å…± {len(documents)} ä¸ªæ–‡æ¡£ç‰‡æ®µ")

        else:
            print("   âš ï¸ å‘é‡æ•°æ®åº“æœªåˆå§‹åŒ–")

        # 5. æ˜¾ç¤ºå­˜å‚¨è¯´æ˜
        print("\n" + "=" * 70)
        print("ğŸ’¡ å­˜å‚¨è¯´æ˜ï¼š")
        print("=" * 70)
        print("""
å‘é‡æ•°æ®åº“ä½¿ç”¨ ChromaDB å­˜å‚¨ï¼ŒåŒ…å«ä»¥ä¸‹ç»„ä»¶ï¼š

1. chroma.sqlite3 (216 KB)
   - SQLiteæ•°æ®åº“æ–‡ä»¶
   - å­˜å‚¨æ–‡æ¡£å…ƒæ•°æ®ã€IDæ˜ å°„ç­‰ç»“æ„åŒ–ä¿¡æ¯

2. {collection_id}/ ç›®å½• (4+ MB)
   - data_level0.bin: å‘é‡åµŒå…¥æ•°æ®ï¼ˆä¸»è¦å­˜å‚¨ç©ºé—´ï¼‰
   - header.bin: ç´¢å¼•å¤´ä¿¡æ¯
   - length.bin: å‘é‡é•¿åº¦ä¿¡æ¯
   - link_lists.bin: HNSWç´¢å¼•çš„é“¾æ¥åˆ—è¡¨

æ•°æ®æµç¨‹ï¼š
   ç½‘é¡µ/æ–‡ä»¶ â†’ æ–‡æœ¬æå– â†’ åˆ†å—(1000å­—ç¬¦) â†’
   åµŒå…¥å‘é‡(1024ç»´) â†’ å­˜å‚¨åˆ°ChromaDB â†’
   æ”¯æŒè¯­ä¹‰æœç´¢

æ¯ä¸ªæ–‡æ¡£ä¼šè¢«ï¼š
   1. åˆ†å‰²æˆå¤šä¸ªç‰‡æ®µï¼ˆchunk_size=1000, overlap=200ï¼‰
   2. æ¯ä¸ªç‰‡æ®µè½¬æ¢ä¸º1024ç»´å‘é‡ï¼ˆè…¾è®¯æ··å…ƒåµŒå…¥æ¨¡å‹ï¼‰
   3. å‘é‡å’Œå…ƒæ•°æ®ä¸€èµ·å­˜å‚¨åˆ°ChromaDB
   4. æŸ¥è¯¢æ—¶é€šè¿‡å‘é‡ç›¸ä¼¼åº¦æ£€ç´¢ç›¸å…³ç‰‡æ®µ
""")

        return True

    except Exception as e:
        print(f"\nâŒ æ£€æŸ¥å¤±è´¥: {str(e)}")
        import traceback
        traceback.print_exc()
        return False


if __name__ == "__main__":
    print("\nè®¾ç½®ç¯å¢ƒç¼–ç ä¸º UTF-8...")
    import sys
    if sys.platform == 'win32':
        import io
        sys.stdout = io.TextIOWrapper(sys.stdout.buffer, encoding='utf-8')

    success = asyncio.run(inspect_knowledge_base())
    sys.exit(0 if success else 1)
