# 流程

您可以把您的智能体想象成一个“虚拟播客工作室”，里面有几个“AI主持人”。您不是和他们实时聊天，而是给他们一个主题，让他们自己聊，然后把聊天内容录制下来给您。

### 逻辑流程重构：如何将“聊天智能体”落地为“播客生成器”

这是一个可行的工作流程：

**输入端 (用户操作):**

1. **定义主题：** 用户输入一个想要探讨的主题，例如“人工智能能否拥有真正的创造力？”（对应子题目3）。
2. **设定角色：** 用户定义参与播客的AI角色。例如：
    - **角色A (李教授):** 乐观的技术专家，说话严谨，喜欢引用数据和论文。
    - **角色B (小雅):** 人文主义者，持谨慎态度，关心技术对社会的影响，语言富有感染力。
    - **角色C (主持人):** 中立，负责引导话题，承上启下。（对应子题目2）
3. **提供素材（可选）：** 用户可以输入一些初始的文本素材或观点作为讨论的起点。（对应子题目1）

**处理端 (您的“智能体”核心):**

1. **内容生成与深度挖掘：**
    - 智能体首先围绕“主题”进行深度分析和内容组织，可能需要检索外部资料来确保“有依据、有见地”。
    - 然后，它会构思一个讨论大纲，包含开场、核心论点碰撞、总结等环节。
2. **多角色剧本模拟：**
    - 这是您“聊天智能体”想法的核心应用。智能体开始**模拟**李教授、小雅和主持人之间的对话。
    - 它需要让角色间的互动“自然”起来，比如：小雅反驳李教授的观点，李教授进行解释，主持人适时抛出新问题，甚至角色间出现一些“接梗玩梗”的非正式交流。（这完美契合子题目1的要求）
    - 这个过程的输出是一份详细的、带有角色标识的播客**剧本**。
3. **音频生成：**
    - 系统将生成的剧本，按照不同角色的“人设”和预设的“音色”，调用TTS（Text-to-Speech）引擎进行转换。
    - 李教授的声音应该沉稳有力，小雅的声音应该温柔但坚定。这需要您对TTS模型进行选择或微调。（对应子题目2的音色要求）

**输出端 (最终作品):**

- 一个 `.mp3` 或 `.wav` 格式的音频文件，内容是三位AI主播围绕指定主题进行的深度、自然、且符合人设的播客节目。

架构设计：

```jsx
[前端/用户界面 (Web UI)] <--> [后端服务 (API Gateway)]
       |
       v
[任务控制器 (Task Controller)]
       |
       +-----------------------------> [1. 素材分析模块 (Analysis Engine)]
       |                                   | (调用 Chat 模型 - Qwen2.5/FireRedChat)
       |                                   v
       +-----------------------------> [2. 剧本生成引擎 (Script Generation Engine)]
       |             |                     | (调用 Chat 模型 - Qwen2.5/FireRedChat)
       |             |                     v
       |             |               [剧本数据 (Structured Script - JSON)]
       |             |
       v             |
[3. 语音合成引擎 (TTS Engine)] <--------+
   | (调用 TTS 模型 - MegaTTS3/CosyVoice/FireRedTTS-2)
   v
[音频后期处理模块 (Post-Processing)]
   | (音频拼接、背景音合成)
   v
[最终音频文件 (.mp3/.wav)] --> [返回给用户]
```

- **前端 (UI):** 可以是一个简单的Web页面，让用户能够方便地填写您设计的“AI虚拟播客定制单”。这是您的可选加分项，强烈建议完成。
- **后端服务 (Backend):** 使用Python (如FastAPI/Flask框架) 搭建API服务，接收前端请求。
- **任务控制器:** 这是业务逻辑的核心，负责接收用户定制单，按顺序调用下面三个AI模块，并管理中间数据（如分析要点、生成的剧本）。
- **AI模块:**
    1. **素材分析:** 调用大模型，执行您的“分析素材提示词”。
    2. **剧本生成:** 调用大模型，执行您的“播客讨论提示词”。
    3. **语音合成:** 遍历最终剧本的每一句对话，根据角色指定的“音色描述”，调用相应的TTS模型生成单句音频。
- **后期处理:** 使用`pydub`等音频处理库，将所有单句音频按顺序拼接起来，还可以选择性地加入开场/结尾的背景音乐（BGM），提升成品质量。

# 开源链接支持

https://github.com/moeru-ai/airi

AI虚拟伴侣

https://github.com/TEN-framework/ten-framework

开源声音平台

https://github.com/mindverse/Second-Me

AI的另一个你

https://github.com/topoteretes/cognee

AI智能体框架

https://github.com/unslothai/unsloth

大模型微调

https://www.xfyun.cn/solutions/sparkos_interactive 

# 模型选择

FireRedTTS-2 https://github.com/FireRedTeam/FireRedTTS2 TTS模型

FireRedChat  Chat生成模型

字节 MegaTTS3

阿里 Qwen2.5-Omni-7B 

 CosyVoice 3

月之暗面 Kimi-Audio

阶跃星辰 Step-Audio 2

## 素材分析（调用大模型）

- **Gemini 2.5 Pro (Google DeepMind)**
    
    推理能力极强，支持长上下文（百万token），适合处理大规模复杂文本数据分析。
    
- **Claude 4 Opus (Anthropic)**
    
    优秀的多步骤推理和自然语言理解，适合深入分析文本素材。
    
- **OpenAI GPT-4.5**
    
    先进的自然语言处理与分析能力，适合高质量素材细节提取。
    
- **Llama 4 Scout (Meta)**
    
    特点是超长上下文支持（千万token），适合处理长篇素材。
    

## 剧本生成（播客讨论脚本）

- **Claude 4 Opus**
    
    优异的对话生成和代码性能，能生成自然流畅的剧本文本。
    
- **Grok 3 (xAI)**
    
    支持实时网络信息集成，能快速生成最新内容脚本。
    
- **Jellypod**
    
    AI原生播客制作平台，支持脚本自动生成并结合角色塑造，实现个性化剧本。
    

## 语音合成（TTS）

- **OpenAI TTS-1 / TTS-1-HD / 40-mini-tts**
    
    多档音质与成本平衡，支持丰富音色调整，适合播客语音合成。
    
- **Wondercraft AI**
    
    专业播客级AI语音平台，拥有多样情感和口音选择，支持高质量广播级输出。
    
- **Google WaveNet**
    
    业界领先的高保真度语音合成技术。
    

# 提示词工程

1.模拟用户真人提示词：

```jsx
# AI虚拟播客定制单

## 1. 核心主题
* **播客主题：** [请在这里填写您想讨论的核心话题，例如：远程工作是未来的趋势还是短暂的泡沫？]
* **播客标题（可选）：** [可以给您的播客起一个吸引人的名字，例如：《未来办公室：云端还是回归？》]

## 2. 风格与氛围
* **讨论氛围：** [请选择或描述，例如：轻松幽默、严肃深入、激烈辩论、温暖治愈]
* **目标时长（预估）：** [例如：5分钟、15分钟、30分钟]
* **语言风格：** [例如：口语化、书面语、学术化、网络化]

## 3. 角色设定 (可添加多个角色)
---
* **角色1**
    * **姓名/代称：** [例如：陈教授]
    * **人设/身份：** [请详细描述，例如：一位50岁的社会学教授，对技术发展持审慎乐观态度，学识渊博，说话喜欢引经据典。]
    * **核心观点：** [例如：认为远程工作虽然提高了效率，但削弱了企业文化和人际连接，需要谨慎推行。]
    * **音色描述（用于TTS）：** [例如：沉稳、浑厚、男中音、语速偏慢]
---
* **角色2**
    * **姓名/代称：** [例如：莉莉]
    * **人设/身份：** [例如：一位25岁的互联网公司程序员，数字游民，极度推崇自由和效率，说话直接，喜欢用最新的网络词汇。]
    * **核心观点：** [例如：坚信远程工作是解放生产力的唯一途径，办公室是过时的产物。]
    * **音色描述（用于TTS）：** [例如：清脆、有活力、女声、语速快]
---
* **角色3 (主持人/中立者)**
    * **姓名/代称：** [例如：阿哲]
    * **人设/身份：** [例如：播客主持人，风格风趣，负责引导流程，提出关键问题，并适时总结。]
    * **核心观点：** [例如：保持中立，但会从听众的角度提出一些实际的挑战和疑问。]
    * **音色描述（用于TTS）：** [例如：标准、有磁性、男声、语速适中]
---

## 4. 补充素材 (可选)
* **背景资料/观点文章：** [请在这里粘贴您希望AI参考的相关文章链接、文本段落或数据。]
```

2.播客讨论提示词：

```jsx
# 任务：生成一期高质量的多角色播客剧本

你现在是一位顶级的播客节目总监兼剧本作家。你的任务是根据以下设定，创作一期完整、流畅、内容深刻且互动自然的播客剧本。

## 播客核心设定
* **主题：** {在此处插入用户输入的“播客主题”}
* **标题：** {在此处插入用户输入的“播客标题”}
* **氛围：** {在此处插入用户输入的“讨论氛围”}
* **预估时长：** {在此处插入用户输入的“目标时长”}

## 角色介绍
{在此处动态生成角色列表}
* **角色：** {角色1姓名}
    * **人设与观点：** {角色1人设与观点}
* **角色：** {角色2姓名}
    * **人设与观点：** {角色2人设与观点}
* **角色：** {角色3姓名}
    * **人设与观点：** {角色3人设与观点}

## 剧本创作核心要求
1.  **结构完整：** 剧本必须包含[开场白]、[主体讨论]和[结束语]三个部分。
    * [开场白]：由主持人引导，介绍本期主题和各位嘉宾。
    * [主体讨论]：围绕主题展开至少2-3个回合的深入交流。确保每个角色都有充分的表达机会。
    * [结束语]：由主持人总结各方观点，并感谢听众。
2.  **互动自然（关键要求）：**
    * **严禁独白：** 避免任何角色进行长篇大论。对话应该是你来我往的。
    * **真实互动：** 角色之间需要有真实的互动，包括但不限于：提问、反驳、赞同、补充、打趣、接梗等。
    * **立场鲜明：** 每个角色必须在对话中始终保持其预设的人设和核心观点。
    * **情感体现：** 对话需要体现出设定的“氛围”，例如在“激烈辩论”中可以有语气强硬的词句，在“轻松幽默”中可以有玩笑和笑声提示。
3.  **内容深度：**
    * 讨论需要有逻辑，有见地，而不仅仅是观点的罗列。
    * {如果用户提供了素材，则添加此条} 参考以下核心要点展开讨论：{在此处插入“分析素材提示词”提取的要点}。
4.  **格式规范：**
    * 每一句对话都必须以“【角色名】：”开头，例如“【阿哲】：”。
    * 可以在对话后用小括号 `()` 标注情绪或动作，例如 `(笑声)`、`(略带激动)`。

请现在开始创作。
```

3.分析素材提示词：

```jsx
# 任务：分析并提炼文本素材的核心要点

你是一位专业的议题分析师。你的任务是阅读并分析以下提供的文本材料，为其后即将进行的播客讨论，提炼出核心的论点、论据、潜在争议点和可以深入探讨的问题。

## 待分析的原始材料
---
{在此处粘贴用户提供的所有文本素材}
---

## 分析要求
请严格按照以下JSON格式输出你的分析结果，不要有任何多余的解释性文字。

{
  "main_thesis": "文本最核心的主张或结论是什么？用一句话概括。",
  "key_arguments": [
    "支撑核心主张的关键论点1",
    "支撑核心主张的关键论点2",
    "支撑核心主张的关键论点3"
  ],
  "supporting_data_or_examples": [
    "文本中提到的关键数据或案例1",
    "文本中提到的关键数据或案例2"
  ],
  "potential_counterarguments": [
    "基于文本内容，可能会引发哪些反驳观点？",
    "文本中是否存在逻辑上值得商榷的地方？"
  ],
  "discussion_questions": [
    "可以引导播客深入讨论的开放性问题1？",
    "针对文本中的某个具体细节，可以提出什么追问？",
    "如何将文本的观点与现实生活联系起来，可以提出什么问题？"
  ]
}
```

# 核心功能

## 剧本生成引擎的进阶策略

单一的“播客讨论提示词”在生成长内容时，可能会出现角色人设漂移、前后逻辑不一致的问题。

在“多轮对话模拟”基础上，我们引入**状态管理器**。

- **执行流程:**
    1. **初始化:** `Task Controller` 根据用户输入，构建一个包含完整设定的**初始Prompt (V1)**，调用LLM生成开场白和第一轮对话。
    2. **状态更新:** 将生成的对话存入一个**对话历史（`conversation_history`）**列表。
    3. **循环Prompt (V2):** `Task Controller` 构建一个更精简的**循环Prompt**，其结构如下：Plaintext
        
        ```jsx
        # 上下文：这是一场关于“{主题}”的播客，参与者有{角色列表}。以下是已进行的对话：
        {conversation_history}
        
        # 任务：请基于以上对话，自然地生成下一轮讨论。
        ## 要求：
        - 保持角色人设和观点。
        - 推动话题深入，或引入新的子论点/冲突。
        - 确保互动性，避免独白。
        - [关键]：现在请 {下一位发言角色} 开始发言。
        ```
        
    4. **智能决定下一位发言者:** 可以在`Task Controller`中编写简单逻辑（如轮流、或让LLM在生成内容结尾附带一个`[NextSpeaker: 角色名]`的建议标签）来决定下一位发言者，使对话流更受控。
    5. **终止条件:** 当对话历史的总字数/时长超过用户设定的“目标时长”，或LLM生成了明确的结束语时，循环终止。

## 语音合成引擎的精细化控制

“音色描述”是好的开始，但我们可以做得更专业。

- **引入SSML (Speech Synthesis Markup Language):** 大部分先进的TTS模型（如字节、阿里的模型）都支持SSML。您可以在剧本生成阶段，让大模型在生成对话的同时，也生成SSML标签。
    - **示例:** `【莉莉】：<speak><prosody rate="fast" pitch="+10%">办公室简直就是生产力的坟墓好吗！</prosody> 我觉得远程办公才是未来！</speak>`
    - **<prosody>标签**可以精细控制**语速(rate)和语调(pitch)**。
    - **<emotion>标签**（部分模型支持）可以直接指定**情绪**。
- **音色映射与克隆:** 您提到的`TEN-framework`、`CosyVoice`等都涉及声音平台和克隆。您可以允许用户上传一小段音频样本来克隆音色，或者预设更丰富的音色库，让用户的“音色描述”能精确匹配到具体的Voice ID上。

音色库建立：

**Voice ID管理:**

1. **预设音色库:** 在系统中建立一个音色库 `VOICE_LIBRARY` (JSON格式)，将您选定TTS模型提供的不同音色进行分类和标记。
    - `{"voice_id": "cosy-male-01", "tags": ["沉稳", "浑厚", "男中音"], "model": "CosyVoice"}`
    - `{"voice_id": "mega-female-02", "tags": ["清脆", "有活力", "女声"], "model": "MegaTTS3"}`
2. **智能匹配:** `Task Controller`接收到用户的“音色描述”（如“沉稳、浑厚”）后，通过简单的关键词匹配算法，从`VOICE_LIBRARY`中选择最匹配的`voice_id`。
3. **音色克隆（高级功能）:** 集成开源声音平台能力，提供一个接口，允许用户上传30秒音频，后端调用模型生成克隆后的`voice_id`，并存入用户的个人音色库。

## 数据策略与模型优化

- **据来源:**
    1. **公开播客数据集:** 在`Hugging Face`等平台寻找开源的中文播客音频+文本字幕数据集。
    2. **对话数据集:** 使用高质量的中文对话或辩论数据集。
    3. **自我生产:** 利用您初步完成的系统，生成大量数据，然后人工筛选出高质量部分。
- **微调（Fine-tuning）策略 (使用 `unsloth` 等工具):**
    1. **Chat模型微调:** 将筛选出的高质量“播客剧本”数据，整理成对话格式，对`Qwen2.5`等模型进行微调。**目标是让模型更懂播客的“行话”、节奏和互动模式**，而不仅仅是通用对话。
    2. **TTS模型微调:** 如果时间和资源允许，可以对TTS模型进行微调，以生成更具表现力和特定风格的音色。

## 评估体系与迭代闭环 (Evaluation System & Iterative Loop)

- **客观指标 (Automated Metrics):**
    - **角色发言均衡度:** 计算每个角色发言的次数和总字数，避免某个角色主导全场。
    - **交互频率:** 计算单位时间内角色切换的频率，高频率通常意味着更自然的互动。
- **主观指标 (Manual Scoring) - 最重要:** 设计一个评分表，邀请他人或评委从以下维度打分（1-5分制）：
    - **角色一致性:** 角色的人设是否从头到尾保持一致？
    - **互动自然度:** 对话听起来像真实的人类互动吗？还是像机器在轮流读稿？
    - **内容深度:** 播客是否引发了思考？是否有信息增量？
    - **音频质量:** 音色是否清晰、悦耳，符合人设？
- **迭代闭环:** 在您的演示UI中加入一个简单的“点赞/点踩”或打分功能。收集用户反馈，用于指导您下一轮的Prompt优化和模型微调。

## 创新亮点与加分项

- **动态音效与背景音乐:** 在音频后期处理模块，智能地加入一些音效（如轻微的笑声、思考时的“嗯...”）和契合讨论氛围的BGM。
- **知识库与RAG (Retrieval-Augmented Generation):** 对于深度话题，在“内容生成”模块前，先用用户的主题去检索相关的学术论文或新闻报道，将摘要作为上下文喂给大模型，确保内容的“有依据、有见地”。
- **自动生成Show Notes:** 在生成播客音频的同时，额外生成一份“本期播客摘要（Show Notes）”，包含核心观点、时间戳和相关链接，这极具实用价值。
- **长期记忆角色:** 借鉴`Second-Me`和`Airi`的理念，让用户创建的角色可以“被保存”。当用户下次用同一个角色制作新播客时，AI能“记住”这个角色之前的观点和经历，展现出成长的连贯性。

## 可能问题

- **风险1：角色人设在长对话中漂移。**
    - **应对:** 核心对策是“状态化循环生成”+ 强化的循环Prompt，不断提醒模型当前的角色设定和历史对话。微调是根治此问题的最佳手段。
- **风险2：TTS合成的音频情感平淡，不像“播客”。**
    - **应对:** 优先选择`MegaTTS3`等以表现力著称的模型；充分利用SSML进行精细控制；在剧本中标注的情感提示词（如`(笑声)`），可以映射到预录的音效片段进行拼接，增加真实感。
- **风险3：生成内容深度不足，观点陈旧。**
    - **应对:** 必须落实RAG。在生成剧本前，强制使用用户主题检索最新的网络文章或学术资料，将摘要注入到Prompt中，确保内容的时效性和深度。
- **风险4：计算资源不足，尤其在微调和批量生成时。**
    - **应对:** 充分利用`Unsloth`等工具的显存优化能力；在云平台（如Google Colab Pro）上进行模型微调；在UI中对生成时长做适当限制，并提供任务队列和异步结果通知，避免用户长时间等待。

# 进行流程

**第一阶段 (Week 1): 基础架构与MVP验证**

- **目标:** 跑通端到端的最小可行产品（MVP）。
- **任务:**
    - [Day 1-2] 搭建FastAPI后端和基础前端页面框架。
    - [Day 3-4] 实现“AI虚拟播客定制单”的数据提交与接收。
    - [Day 5-6] 实现**单次调用**的剧本生成和TTS合成，能生成一段简短的、拼接好的音频。
    - [Day 7] 完成基础部署，确保流程没有阻塞。
- **产出:** 一个可以输入主题、角色，并生成一段1分钟左右播客音频的内部版本。

**第二阶段 (Week 2-3): 核心功能深化与模型优化**

- **目标:** 实现所有高级功能，开始模型优化。
- **任务:**
    - [Week 2] 实现“状态化循环生成”机制；集成SSML，提升语音表现力；加入动态BGM和音效处理。
    - [Week 3] 准备播客微调数据集；使用`Unsloth`对Chat模型进行微调；搭建RAG知识库检索功能。
- **产出:** 功能完备、效果显著提升的Beta版本。微调后的模型在播客对话的“感觉”上应优于基础模型。

**第三阶段 (Week 4): 集成、评估与交付准备**

- **目标:** 打磨产品，完成所有竞赛交付物。
- **任务:**
    - [Day 1-3] 对UI进行美化，提升用户体验；根据主观评估体系，对系统进行最后调优。
    - [Day 4-5] 撰写技术报告，录制演示视频。
    - [Day 6-7] 整理代码，编写详尽的`README.md`，使用Docker打包，确保可复现性。
- **产出:** 全部竞赛交付物，准备提交。