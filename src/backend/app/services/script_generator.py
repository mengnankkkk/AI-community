import openai
import google.generativeai as genai
import json
import re
from typing import Dict, Any, List, Optional
from ..models.podcast import PodcastCustomForm, PodcastScript, ScriptDialogue
from ..core.config import settings
from .rag_knowledge_service import RAGKnowledgeService
from ..utils.text_cleaner import clean_for_tts


class FallbackResponse:
    """å›é€€å“åº”å¯¹è±¡"""
    def __init__(self, content: str):
        self.choices = [FallbackChoice(content)]


class FallbackChoice:
    """å›é€€é€‰æ‹©å¯¹è±¡"""
    def __init__(self, content: str):
        self.message = FallbackMessage(content)


class FallbackMessage:
    """å›é€€æ¶ˆæ¯å¯¹è±¡"""
    def __init__(self, content: str):
        self.content = content


class FallbackCompletions:
    """å›é€€èŠå¤©å®ŒæˆæœåŠ¡"""
    async def create(self, model: str, messages: List[Dict], temperature: float = 0.8, **kwargs):
        """ç”Ÿæˆå›é€€å†…å®¹"""
        # è·å–ç”¨æˆ·çš„è¾“å…¥
        user_input = ""
        for message in messages:
            if message.get("role") == "user":
                user_input = message.get("content", "")
                break

        # ä»è¾“å…¥ä¸­æå–è§’è‰²ä¿¡æ¯
        characters = self._extract_characters(user_input)
        topic = self._extract_topic(user_input)

        if not characters:
            characters = ["ä¸»æŒäºº", "å˜‰å®¾"]

        # ç®€å•çš„æ¨¡æ¿ç”Ÿæˆé€»è¾‘
        if "å¼€åœºç™½" in user_input or "ç¬¬ä¸€è½®å¯¹è¯" in user_input:
            content = self._generate_opening(characters, topic)
        elif "ç»§ç»­å¯¹è¯" in user_input:
            content = self._generate_continuation(characters, topic)
        elif "ç»“æŸè¯­" in user_input:
            content = self._generate_ending(characters[0])
        else:
            # é€šç”¨å›å¤
            content = self._generate_opening(characters, topic)

        return FallbackResponse(content)

    def _extract_characters(self, user_input: str) -> List[str]:
        """ä»è¾“å…¥ä¸­æå–è§’è‰²åç§°"""
        characters = []
        lines = user_input.split('\n')

        for line in lines:
            if '**è§’è‰²ï¼š**' in line:
                # æå–è§’è‰²åç§°ï¼Œä¾‹å¦‚ï¼š"* **è§’è‰²ï¼š** æåšå£«"
                parts = line.split('**è§’è‰²ï¼š**')
                if len(parts) > 1:
                    char_name = parts[1].strip().split('\n')[0].strip()
                    if char_name:
                        characters.append(char_name)

        return characters[:3]  # æœ€å¤š3ä¸ªè§’è‰²

    def _extract_topic(self, user_input: str) -> str:
        """ä»è¾“å…¥ä¸­æå–ä¸»é¢˜"""
        lines = user_input.split('\n')

        for line in lines:
            if '**ä¸»é¢˜ï¼š**' in line:
                parts = line.split('**ä¸»é¢˜ï¼š**')
                if len(parts) > 1:
                    return parts[1].strip()

        return "æœ‰è¶£çš„è¯é¢˜"

    def _generate_opening(self, characters: List[str], topic: str) -> str:
        """ç”Ÿæˆå¼€åœºç™½"""
        host = characters[0] if characters else "ä¸»æŒäºº"
        guest = characters[1] if len(characters) > 1 else "å˜‰å®¾"

        return f"""{{
  "dialogues": [
    {{
      "character_name": "{host}",
      "content": "æ¬¢è¿å¤§å®¶æ”¶å¬ä»Šå¤©çš„æ’­å®¢èŠ‚ç›®ï¼ä»Šå¤©æˆ‘ä»¬è¦æ·±å…¥æ¢è®¨ä¸€ä¸ªéå¸¸é‡è¦çš„è¯é¢˜ï¼š{topic}ã€‚",
      "emotion": "å¼€å¿ƒ"
    }},
    {{
      "character_name": "{guest}",
      "content": "è°¢è°¢é‚€è¯·ï¼{topic}ç¡®å®æ˜¯ä¸€ä¸ªå€¼å¾—æˆ‘ä»¬è®¤çœŸè®¨è®ºçš„è®®é¢˜ï¼Œæˆ‘å¾ˆé«˜å…´èƒ½åœ¨è¿™é‡Œä¸å¤§å®¶åˆ†äº«æˆ‘çš„è§‚ç‚¹ã€‚",
      "emotion": "å‹å¥½"
    }},
    {{
      "character_name": "{host}",
      "content": "é‚£ä¹ˆè®©æˆ‘ä»¬å…ˆä»åŸºæœ¬æ¦‚å¿µå¼€å§‹èŠèµ·ï¼Œæ‚¨è®¤ä¸ºè¿™ä¸ªè¯é¢˜çš„æ ¸å¿ƒæ˜¯ä»€ä¹ˆï¼Ÿ",
      "emotion": "å¥½å¥‡"
    }}
  ]
}}"""

    def _generate_continuation(self, characters: List[str], topic: str) -> str:
        """ç”Ÿæˆç»§ç»­å¯¹è¯"""
        speaker1 = characters[0] if characters else "ä¸»æŒäºº"
        speaker2 = characters[1] if len(characters) > 1 else "å˜‰å®¾"

        return f"""{{
  "dialogues": [
    {{
      "character_name": "{speaker2}",
      "content": "è¿™ä¸ªè§‚ç‚¹ç¡®å®å¾ˆæœ‰æ„æ€ã€‚æˆ‘è®¤ä¸ºåœ¨è®¨è®º{topic}æ—¶ï¼Œæˆ‘ä»¬è¿˜éœ€è¦è€ƒè™‘æ›´å¤šçš„å®é™…å› ç´ å’Œæ½œåœ¨å½±å“ã€‚",
      "emotion": "æ€è€ƒ"
    }},
    {{
      "character_name": "{speaker1}",
      "content": "æ‚¨è¯´å¾—éå¸¸å¯¹ï¼èƒ½å¦è¯¦ç»†å±•å¼€ä¸€ä¸‹æ‚¨çš„çœ‹æ³•ï¼Ÿæˆ‘æƒ³å¬ä¼—æœ‹å‹ä»¬ä¹Ÿå¾ˆæ„Ÿå…´è¶£ã€‚",
      "emotion": "å¥½å¥‡"
    }}
  ]
}}"""

    def _generate_ending(self, host_name: str) -> str:
        """ç”Ÿæˆç»“æŸè¯­"""
        return f"""{{
  "dialogues": [
    {{
      "character_name": "{host_name}",
      "content": "ä»Šå¤©çš„è®¨è®ºéå¸¸ç²¾å½©ï¼Œæ„Ÿè°¢å„ä½å˜‰å®¾çš„æ·±å…¥åˆ†æï¼Œä¹Ÿæ„Ÿè°¢å¬ä¼—æœ‹å‹ä»¬çš„æ”¶å¬ï¼æˆ‘ä»¬ä¸‹æœŸèŠ‚ç›®å†è§ï¼",
      "emotion": "æ¸©æš–"
    }}
  ]
}}"""


class FallbackClient:
    """å›é€€å®¢æˆ·ç«¯ï¼ˆç”¨äºæ¼”ç¤ºå’Œæµ‹è¯•ï¼‰"""
    def __init__(self):
        self.chat = self
        self.completions = FallbackCompletions()


class ScriptGenerator:
    def __init__(self):
        # é…ç½®Geminiç”¨äºç´ æåˆ†æ
        if settings.gemini_api_key:
            genai.configure(api_key=settings.gemini_api_key)

        # é…ç½®DeepSeekç”¨äºå‰§æœ¬ç”Ÿæˆ
        # ä¸´æ—¶å¼ºåˆ¶ä½¿ç”¨å›é€€æ¨¡å¼ï¼Œé¿å…Gradio Spaceé—®é¢˜
        use_gradio = False  # å¼ºåˆ¶ç¦ç”¨

        if use_gradio and getattr(settings, 'use_gradio_deepseek', False):
            # ä½¿ç”¨Gradio Spaceæ¨¡å¼
            try:
                from .gradio_adapter import MockOpenAIClient
                self.deepseek_client = MockOpenAIClient(
                    api_key="gradio_mode",
                    base_url="gradio_mode"
                )
                print("ä½¿ç”¨Gradio Spaceæ¨¡å¼")
            except ImportError:
                print("Gradioé€‚é…å™¨å¯¼å…¥å¤±è´¥ï¼Œå›é€€åˆ°æ ‡å‡†APIæ¨¡å¼")
                # å¦‚æœæ²¡æœ‰é…ç½®æœ‰æ•ˆçš„DeepSeekå¯†é’¥ï¼Œä½¿ç”¨ä¸€ä¸ªé»˜è®¤çš„é”™è¯¯å¤„ç†å®¢æˆ·ç«¯
                self.deepseek_client = self._create_fallback_client()
        else:
            # ä½¿ç”¨æ ‡å‡†OpenAIå…¼å®¹APIæ¨¡å¼æˆ–å›é€€æ¨¡å¼
            # å®šä¹‰æ— æ•ˆçš„API keyåˆ—è¡¨ï¼ˆä»…å ä½ç¬¦ï¼‰
            invalid_keys = [
                "",
                "your_actual_deepseek_api_key_here",
                "your_valid_hunyuan_api_key_here",
                "your_openai_api_key_here"
            ]

            # æ£€æŸ¥API keyæ˜¯å¦æœ‰æ•ˆ
            if settings.deepseek_api_key and settings.deepseek_api_key not in invalid_keys:
                try:
                    # ä½¿ç”¨å¼‚æ­¥å®¢æˆ·ç«¯ï¼ˆAsyncOpenAIï¼‰ç”¨äºå¼‚æ­¥å‡½æ•°
                    self.deepseek_client = openai.AsyncOpenAI(
                        api_key=settings.deepseek_api_key,
                        base_url=settings.deepseek_base_url
                    )
                    print(f"[é…ç½®] ä½¿ç”¨è…¾è®¯æ··å…ƒAPIæ¨¡å¼ï¼ˆå¼‚æ­¥ï¼‰")
                    print(f"[é…ç½®] Base URL: {settings.deepseek_base_url}")
                    print(f"[é…ç½®] Model: {settings.deepseek_model}")
                    print(f"[é…ç½®] API Key (å‰10ä½): {settings.deepseek_api_key[:10]}...")
                except Exception as e:
                    print(f"[é”™è¯¯] APIå®¢æˆ·ç«¯åˆå§‹åŒ–å¤±è´¥: {str(e)}")
                    print("[å›é€€] ä½¿ç”¨æ¨¡æ¿æ¨¡å¼")
                    self.deepseek_client = self._create_fallback_client()
            else:
                print("[é…ç½®] æœªé…ç½®æœ‰æ•ˆAPI Keyï¼Œä½¿ç”¨å›é€€æ¨¡æ¿æ¨¡å¼")
                self.deepseek_client = self._create_fallback_client()

        # åˆå§‹åŒ–RAGçŸ¥è¯†åº“æœåŠ¡
        self.rag_service = RAGKnowledgeService()

        # çŠ¶æ€åŒ–å¾ªç¯ç”Ÿæˆç›¸å…³å±æ€§
        self.conversation_history: List[ScriptDialogue] = []
        self.characters_list: List[str] = []
        self.current_speaker_index: int = 0
        self.target_word_count: int = 0
        self.current_word_count: int = 0

        # æ€§èƒ½ä¼˜åŒ–ï¼šç¼“å­˜æœºåˆ¶
        self._rag_cache = {}  # RAGæ£€ç´¢ç»“æœç¼“å­˜
        self._structure_cache = {}  # ç»“æ„è§„åˆ’ç¼“å­˜
        self._cache_max_size = 50  # æœ€å¤§ç¼“å­˜æ¡ç›®æ•°
        self._cache_enabled = True  # æ˜¯å¦å¯ç”¨ç¼“å­˜

    def _get_cache_key(self, prefix: str, *args) -> str:
        """ç”Ÿæˆç¼“å­˜é”®"""
        import hashlib
        content = prefix + "_" + "_".join(str(arg) for arg in args)
        return hashlib.md5(content.encode()).hexdigest()

    def _get_from_cache(self, cache_dict: dict, key: str):
        """ä»ç¼“å­˜è·å–æ•°æ®"""
        if not self._cache_enabled:
            return None
        return cache_dict.get(key)

    def _set_to_cache(self, cache_dict: dict, key: str, value: Any):
        """è®¾ç½®ç¼“å­˜æ•°æ®"""
        if not self._cache_enabled:
            return

        # ç®€å•çš„LRUç­–ç•¥ï¼šå¦‚æœç¼“å­˜æ»¡äº†ï¼Œæ¸…é™¤æœ€æ—§çš„ä¸€åŠ
        if len(cache_dict) >= self._cache_max_size:
            keys_to_remove = list(cache_dict.keys())[:self._cache_max_size // 2]
            for k in keys_to_remove:
                del cache_dict[k]

        cache_dict[key] = value

    def generate_analysis_prompt(self, materials: str) -> str:
        """ç”Ÿæˆç´ æåˆ†ææç¤ºè¯ - é’ˆå¯¹ Gemini 2.5 Flash ä¼˜åŒ–"""
        return f"""# ä»»åŠ¡ï¼šæ·±åº¦åˆ†ææ–‡æœ¬ç´ æï¼Œä¸ºæ’­å®¢åˆ›ä½œæä¾›ç»“æ„åŒ–è§è§£

ä½ æ˜¯ä¸€ä½é¡¶å°–çš„å†…å®¹åˆ†æä¸“å®¶å’Œæ’­å®¢é¡¾é—®ã€‚ä½ å°†æ·±å…¥åˆ†æä»¥ä¸‹æ–‡æœ¬ææ–™ï¼Œæç‚¼å‡ºé€‚åˆæ’­å®¢è®¨è®ºçš„æ ¸å¿ƒè¦ç‚¹ã€äº‰è®®è¯é¢˜å’Œæ·±åº¦é—®é¢˜ã€‚

## åˆ†ææ–¹æ³•è®º
é‡‡ç”¨"ä¸‰å±‚åˆ†ææ³•"ï¼š
1. **è¡¨å±‚åˆ†æ**ï¼šæå–æ˜ç¡®é™ˆè¿°çš„äº‹å®ã€è§‚ç‚¹å’Œæ•°æ®
2. **æ·±å±‚åˆ†æ**ï¼šæŒ–æ˜éšå«çš„å‡è®¾ã€é€»è¾‘é“¾æ¡å’Œæ½œåœ¨çŸ›ç›¾
3. **åº”ç”¨åˆ†æ**ï¼šè½¬åŒ–ä¸ºå¼•äººå…¥èƒœçš„æ’­å®¢è®¨è®ºç‚¹

## å¾…åˆ†æçš„åŸå§‹ææ–™
---
{materials}
---

## åˆ†ææ­¥éª¤ï¼ˆå†…éƒ¨æ€è€ƒï¼Œä¸è¦è¾“å‡ºï¼‰
1. å¿«é€Ÿé˜…è¯»å…¨æ–‡ï¼ŒæŠŠæ¡æ•´ä½“æ¡†æ¶
2. è¯†åˆ«æ ¸å¿ƒè®ºç‚¹å’Œæ”¯æ’‘è®ºæ®
3. å‘ç°æ½œåœ¨çš„äº‰è®®ç‚¹å’Œæœªè§£å†³é—®é¢˜
4. æ„æ€å¼•å¯¼æ·±åº¦è®¨è®ºçš„é—®é¢˜
5. æç‚¼å¯ä¾›æ’­å®¢ä½¿ç”¨çš„å…³é”®ä¿¡æ¯

## è¾“å‡ºæ ¼å¼è¦æ±‚
**å¿…é¡»ä¸¥æ ¼æŒ‰ç…§ä»¥ä¸‹ JSON æ ¼å¼è¾“å‡ºï¼Œä¸è¦æ·»åŠ ä»»ä½•ä»£ç å—æ ‡è®°ï¼ˆå¦‚ ```jsonï¼‰ï¼š**

{{
  "main_thesis": "ç”¨ä¸€å¥è¯ï¼ˆ30-50å­—ï¼‰æ¦‚æ‹¬æ–‡æœ¬çš„æ ¸å¿ƒä¸»å¼ æˆ–ç»“è®º",
  "key_arguments": [
    "æ”¯æ’‘æ ¸å¿ƒä¸»å¼ çš„å…³é”®è®ºç‚¹1ï¼ˆå…·ä½“ã€æ¸…æ™°ã€å¯è¾©è®ºï¼‰",
    "æ”¯æ’‘æ ¸å¿ƒä¸»å¼ çš„å…³é”®è®ºç‚¹2",
    "æ”¯æ’‘æ ¸å¿ƒä¸»å¼ çš„å…³é”®è®ºç‚¹3",
    "å¦‚æœ‰å¿…è¦ï¼Œå¯æ·»åŠ ç¬¬4ã€5ä¸ªè®ºç‚¹"
  ],
  "supporting_data_or_examples": [
    "å…³é”®æ•°æ®æˆ–æ¡ˆä¾‹1ï¼šå…·ä½“æ•°å­—ã€å¼•äººæ³¨ç›®çš„äº‹å®æˆ–ç”ŸåŠ¨çš„ä¾‹å­",
    "å…³é”®æ•°æ®æˆ–æ¡ˆä¾‹2ï¼šæ³¨é‡å¯éªŒè¯æ€§å’Œè¯´æœåŠ›",
    "å…³é”®æ•°æ®æˆ–æ¡ˆä¾‹3"
  ],
  "potential_counterarguments": [
    "åé©³è§‚ç‚¹1ï¼šä»ä¸åŒè§†è§’è´¨ç–‘æ ¸å¿ƒä¸»å¼ ",
    "é€»è¾‘æ¼æ´1ï¼šæ–‡æœ¬ä¸­å¯èƒ½å­˜åœ¨çš„æ¨ç†é—®é¢˜",
    "æ½œåœ¨äº‰è®®1ï¼šå®¹æ˜“å¼•å‘åˆ†æ­§çš„è§‚ç‚¹æˆ–å‡è®¾"
  ],
  "discussion_questions": [
    "æ·±åº¦é—®é¢˜1ï¼šä¸ºä»€ä¹ˆã€æ ¸å¿ƒæ¦‚å¿µã€‘ä¼šå¯¼è‡´ã€æŸç§ç»“æœã€‘ï¼Ÿ",
    "åº”ç”¨é—®é¢˜1ï¼šè¿™ä¸ªè§‚ç‚¹å¦‚ä½•å½±å“ã€å…·ä½“åœºæ™¯/è¡Œä¸š/ç¾¤ä½“ã€‘ï¼Ÿ",
    "æ‰¹åˆ¤é—®é¢˜1ï¼šä½œè€…çš„å‡è®¾ã€å…·ä½“å‡è®¾ã€‘æ˜¯å¦æˆç«‹ï¼Ÿæœ‰å“ªäº›ä¾‹å¤–æƒ…å†µï¼Ÿ",
    "å±•æœ›é—®é¢˜1ï¼šå¦‚æœã€æ ¸å¿ƒä¸»å¼ ã€‘ç»§ç»­å‘å±•ï¼Œ5å¹´åä¼šå‘ç”Ÿä»€ä¹ˆï¼Ÿ"
  ],
  "podcast_hooks": [
    "å¼€åœºé’©å­ï¼šèƒ½ç«‹å³å¸å¼•å¬ä¼—çš„æƒŠäººäº‹å®æˆ–äº‰è®®è§‚ç‚¹",
    "æƒ…æ„Ÿå…±é¸£ç‚¹ï¼šä¸å¬ä¼—æ—¥å¸¸ç»å†ç›¸å…³çš„å…·ä½“åœºæ™¯",
    "çŸ¥è¯†ç›²åŒºï¼šå¤§å¤šæ•°äººä¸çŸ¥é“ä½†åº”è¯¥äº†è§£çš„ä¿¡æ¯"
  ]
}}

## è´¨é‡æ ‡å‡†
- æ¯ä¸ªè¦ç‚¹éƒ½è¦å…·ä½“ã€å¯æ“ä½œã€æœ‰æ´å¯ŸåŠ›
- é¿å…ç©ºæ´çš„æ€»ç»“æ€§è¯­è¨€
- ä¼˜å…ˆé€‰æ‹©æœ‰äº‰è®®æ€§ã€èƒ½å¼•å‘æ€è€ƒçš„å†…å®¹
- ç¡®ä¿æ‰€æœ‰å­—æ®µéƒ½æœ‰å®è´¨æ€§å†…å®¹ï¼ˆä¸å°‘äº3ä¸ªæ¡ç›®ï¼‰

ç°åœ¨å¼€å§‹åˆ†æï¼Œç›´æ¥è¾“å‡º JSON ç»“æœï¼š"""

    async def analyze_materials(self, materials: str) -> Dict[str, Any]:
        """ä½¿ç”¨ Gemini 2.5 Flash åˆ†æç´ æå†…å®¹ - å¢å¼ºç‰ˆ

        ç‰¹æ€§ï¼š
        - è‡ªåŠ¨é‡è¯•æœºåˆ¶ï¼ˆæœ€å¤š3æ¬¡ï¼‰
        - ä¼˜åŒ–çš„ç”Ÿæˆå‚æ•°é…ç½®
        - JSON æå–å’ŒéªŒè¯
        - è¯¦ç»†çš„é”™è¯¯æ—¥å¿—
        - å›é€€æœºåˆ¶
        """
        if not materials or not materials.strip():
            print("[åˆ†æ] ç´ æä¸ºç©ºï¼Œè·³è¿‡åˆ†æ")
            return {}

        prompt = self.generate_analysis_prompt(materials)
        max_retries = 3

        for attempt in range(max_retries):
            try:
                print(f"[åˆ†æ] ç¬¬ {attempt + 1}/{max_retries} æ¬¡å°è¯•ä½¿ç”¨ Gemini 2.5 Flash åˆ†æç´ æ...")

                # é…ç½® Gemini 2.5 Flash çš„ç”Ÿæˆå‚æ•°
                generation_config = {
                    "temperature": 0.4,  # é™ä½æ¸©åº¦ä»¥è·å¾—æ›´ç¨³å®šçš„åˆ†æç»“æœ
                    "top_p": 0.95,
                    "top_k": 40,
                    "max_output_tokens": 4096,  # å…è®¸è¯¦ç»†çš„åˆ†æè¾“å‡º
                    "response_mime_type": "application/json",  # å¼ºåˆ¶ JSON è¾“å‡º
                }

                # ä½¿ç”¨ Gemini è¿›è¡Œåˆ†æ
                model = genai.GenerativeModel(
                    model_name=settings.gemini_model,
                    generation_config=generation_config
                )

                response = model.generate_content(prompt)
                result_text = response.text.strip()

                print(f"[åˆ†æ] Gemini å“åº”é•¿åº¦: {len(result_text)} å­—ç¬¦")

                # æå– JSONï¼ˆå¤„ç†å¯èƒ½çš„ä»£ç å—åŒ…è£¹ï¼‰
                result_text = self._extract_json_from_response(result_text)

                # è§£æ JSON
                analysis_result = json.loads(result_text)

                # éªŒè¯ç»“æœç»“æ„
                if self._validate_analysis_result(analysis_result):
                    print(f"[åˆ†æ] æˆåŠŸå®Œæˆç´ æåˆ†æ")
                    print(f"  - æ ¸å¿ƒä¸»å¼ : {analysis_result.get('main_thesis', '')[:50]}...")
                    print(f"  - å…³é”®è®ºç‚¹: {len(analysis_result.get('key_arguments', []))} ä¸ª")
                    print(f"  - è®¨è®ºé—®é¢˜: {len(analysis_result.get('discussion_questions', []))} ä¸ª")
                    if 'podcast_hooks' in analysis_result:
                        print(f"  - æ’­å®¢é’©å­: {len(analysis_result.get('podcast_hooks', []))} ä¸ª")
                    return analysis_result
                else:
                    print(f"[åˆ†æ] ç¬¬ {attempt + 1} æ¬¡ç»“æœéªŒè¯å¤±è´¥ï¼Œç»“æ„ä¸å®Œæ•´")
                    if attempt < max_retries - 1:
                        print(f"[åˆ†æ] å°†è¿›è¡Œé‡è¯•...")
                        continue

            except json.JSONDecodeError as e:
                print(f"[åˆ†æ] JSON è§£æå¤±è´¥ (å°è¯• {attempt + 1}/{max_retries}): {str(e)}")
                print(f"[åˆ†æ] å“åº”å†…å®¹å‰500å­—ç¬¦: {result_text[:500] if 'result_text' in locals() else 'N/A'}")
                if attempt < max_retries - 1:
                    print(f"[åˆ†æ] å°†è¿›è¡Œé‡è¯•...")
                    continue

            except Exception as e:
                print(f"[åˆ†æ] Gemini ç´ æåˆ†æå¤±è´¥ (å°è¯• {attempt + 1}/{max_retries}): {str(e)}")
                print(f"[åˆ†æ] é”™è¯¯ç±»å‹: {type(e).__name__}")
                if attempt < max_retries - 1:
                    print(f"[åˆ†æ] å°†è¿›è¡Œé‡è¯•...")
                    import asyncio
                    await asyncio.sleep(1)  # ç­‰å¾…1ç§’åé‡è¯•
                    continue

        # æ‰€æœ‰é‡è¯•éƒ½å¤±è´¥ï¼Œè¿”å›åŸºç¡€åˆ†æç»“æœ
        print(f"[åˆ†æ] æ‰€æœ‰é‡è¯•å‡å¤±è´¥ï¼Œè¿”å›åŸºç¡€åˆ†ææ¨¡æ¿")
        return self._get_fallback_analysis(materials)

    def _extract_json_from_response(self, text: str) -> str:
        """ä»å“åº”ä¸­æå– JSON å†…å®¹

        å¤„ç†ä»¥ä¸‹æƒ…å†µï¼š
        - çº¯ JSON
        - ```json ... ``` åŒ…è£¹çš„ JSON
        - ```... ``` åŒ…è£¹çš„ JSON
        """
        text = text.strip()

        # å¦‚æœè¢«ä»£ç å—åŒ…è£¹ï¼Œæå–å†…å®¹
        if text.startswith("```"):
            # ç§»é™¤å¼€å¤´çš„ ```json æˆ– ```
            text = re.sub(r'^```(?:json)?\s*\n?', '', text)
            # ç§»é™¤ç»“å°¾çš„ ```
            text = re.sub(r'\n?```\s*$', '', text)
            text = text.strip()

        return text

    def _validate_analysis_result(self, result: Dict[str, Any]) -> bool:
        """éªŒè¯åˆ†æç»“æœçš„ç»“æ„å®Œæ•´æ€§"""
        required_fields = [
            "main_thesis",
            "key_arguments",
            "supporting_data_or_examples",
            "potential_counterarguments",
            "discussion_questions"
        ]

        for field in required_fields:
            if field not in result:
                print(f"[éªŒè¯] ç¼ºå°‘å¿…éœ€å­—æ®µ: {field}")
                return False

            # æ£€æŸ¥åˆ—è¡¨å­—æ®µè‡³å°‘æœ‰ä¸€ä¸ªå…ƒç´ 
            if isinstance(result[field], list) and len(result[field]) == 0:
                print(f"[éªŒè¯] å­—æ®µ {field} ä¸ºç©ºåˆ—è¡¨")
                return False

        return True

    def _get_fallback_analysis(self, materials: str) -> Dict[str, Any]:
        """ç”Ÿæˆå›é€€åˆ†æç»“æœï¼ˆå½“ Gemini åˆ†æå¤±è´¥æ—¶ï¼‰"""
        # ç®€å•çš„å…³é”®è¯æå–
        words = materials.split()[:100]  # å–å‰100ä¸ªè¯
        preview = " ".join(words)

        return {
            "main_thesis": "åŸºäºæä¾›çš„ç´ æå†…å®¹è¿›è¡Œæ·±å…¥è®¨è®º",
            "key_arguments": [
                "ç´ æä¸­æåˆ°çš„æ ¸å¿ƒè§‚ç‚¹å’Œè®ºæ®",
                "ç›¸å…³é¢†åŸŸçš„ä¸“ä¸šè§è§£",
                "å®è·µæ¡ˆä¾‹å’Œæ•°æ®æ”¯æ’‘"
            ],
            "supporting_data_or_examples": [
                f"ç´ ææ‘˜è¦: {preview[:200]}...",
                "ç›¸å…³èƒŒæ™¯ä¿¡æ¯å’Œä¸Šä¸‹æ–‡"
            ],
            "potential_counterarguments": [
                "ä¸åŒè§†è§’çš„è§‚ç‚¹å’Œè´¨ç–‘",
                "éœ€è¦è¿›ä¸€æ­¥éªŒè¯çš„å‡è®¾"
            ],
            "discussion_questions": [
                "è¿™ä¸ªè§‚ç‚¹çš„æ ¸å¿ƒä»·å€¼æ˜¯ä»€ä¹ˆï¼Ÿ",
                "åœ¨å®é™…åº”ç”¨ä¸­ä¼šé‡åˆ°å“ªäº›æŒ‘æˆ˜ï¼Ÿ",
                "å¦‚ä½•è¯„ä¼°è¿™ä¸ªè§‚ç‚¹çš„é•¿æœŸå½±å“ï¼Ÿ"
            ],
            "podcast_hooks": [
                "å¼•å‘æ€è€ƒçš„æ ¸å¿ƒè®®é¢˜",
                "ä¸å¬ä¼—ç›¸å…³çš„å®é™…åœºæ™¯",
                "å€¼å¾—æ·±å…¥æ¢è®¨çš„é—®é¢˜"
            ],
            "_fallback": True  # æ ‡è®°è¿™æ˜¯å›é€€ç»“æœ
        }

    def _calculate_knowledge_confidence(self, knowledge_point: Dict[str, Any]) -> float:
        """è®¡ç®—RAGçŸ¥è¯†ç‚¹çš„ç½®ä¿¡åº¦è¯„åˆ†

        åŸºäºæ¥æºç±»å‹å’Œå…ƒæ•°æ®è¯„ä¼°çŸ¥è¯†å¯ä¿¡åº¦ï¼š
        - å­¦æœ¯è®ºæ–‡ã€å®˜æ–¹æ–‡æ¡£: 0.9-1.0 (é«˜å¯ä¿¡åº¦)
        - ä¸“ä¸šç½‘ç«™ã€è¡Œä¸šæŠ¥å‘Š: 0.7-0.9 (ä¸­é«˜å¯ä¿¡åº¦)
        - ä¸€èˆ¬ç½‘é¡µã€åšå®¢: 0.5-0.7 (ä¸­ç­‰å¯ä¿¡åº¦)
        - ç¤¾äº¤åª’ä½“ã€è®ºå›: 0.3-0.5 (ä½å¯ä¿¡åº¦)
        """
        source = knowledge_point.get("source", "").lower()
        metadata = knowledge_point.get("metadata", {})

        # åŸºç¡€ç½®ä¿¡åº¦
        base_confidence = 0.6

        # æ ¹æ®æ¥æºç±»å‹è°ƒæ•´
        if any(keyword in source for keyword in ['.pdf', 'arxiv', 'doi', 'paper', 'journal']):
            # å­¦æœ¯è®ºæ–‡
            base_confidence = 0.95
        elif any(keyword in source for keyword in ['.gov', '.edu', 'official', 'documentation']):
            # å®˜æ–¹æ–‡æ¡£ã€æ•™è‚²æœºæ„
            base_confidence = 0.90
        elif any(keyword in source for keyword in ['wikipedia', 'wiki']):
            # ç»´åŸºç™¾ç§‘ï¼ˆç›¸å¯¹å¯é ä½†éœ€éªŒè¯ï¼‰
            base_confidence = 0.75
        elif any(keyword in source for keyword in ['blog', 'medium', 'zhihu', 'csdn']):
            # æŠ€æœ¯åšå®¢ã€ç¤¾åŒº
            base_confidence = 0.65
        elif any(keyword in source for keyword in ['twitter', 'weibo', 'forum', 'reddit']):
            # ç¤¾äº¤åª’ä½“ã€è®ºå›
            base_confidence = 0.45

        # æ ¹æ®å…ƒæ•°æ®å¾®è°ƒ
        if metadata.get("type") == "file":
            # æœ¬åœ°æ–‡ä»¶ä¸€èˆ¬æ˜¯ç”¨æˆ·æä¾›çš„ï¼Œå¯ä¿¡åº¦è¾ƒé«˜
            base_confidence = min(base_confidence + 0.1, 1.0)

        # å†…å®¹é•¿åº¦è°ƒæ•´ï¼ˆè¿‡çŸ­çš„å†…å®¹å¯èƒ½ä¸å®Œæ•´ï¼‰
        content_length = len(knowledge_point.get("content", ""))
        if content_length < 50:
            base_confidence *= 0.8
        elif content_length > 500:
            base_confidence = min(base_confidence + 0.05, 1.0)

        return round(base_confidence, 2)

    def _validate_against_knowledge(self, dialogue_content: str,
                                   rag_context: Dict[str, Any] = None) -> Dict[str, Any]:
        """äº‹å®æ ¡éªŒå±‚ï¼šæ£€æµ‹ç”Ÿæˆå†…å®¹ä¸RAGçŸ¥è¯†çš„å†²çª

        è¿”å›æ ¼å¼ï¼š
        {
            "is_valid": bool,          # æ˜¯å¦é€šè¿‡æ ¡éªŒ
            "confidence": float,       # æ•´ä½“å¯ä¿¡åº¦
            "warnings": List[str],     # è­¦å‘Šä¿¡æ¯
            "conflicting_facts": List  # å¯èƒ½å­˜åœ¨çš„å†²çªäº‹å®
        }
        """
        validation_result = {
            "is_valid": True,
            "confidence": 0.8,
            "warnings": [],
            "conflicting_facts": []
        }

        if not rag_context or not rag_context.get("knowledge_points"):
            # æ²¡æœ‰RAGçŸ¥è¯†å‚è€ƒï¼Œé»˜è®¤é€šè¿‡
            validation_result["confidence"] = 0.6
            validation_result["warnings"].append("æ— RAGçŸ¥è¯†å‚è€ƒï¼Œæ— æ³•è¿›è¡Œäº‹å®æ ¡éªŒ")
            return validation_result

        # æå–å¯¹è¯ä¸­çš„å…³é”®æ•°å­—å’Œæ–­è¨€ï¼ˆç®€åŒ–ç‰ˆï¼‰
        import re

        # æ£€æµ‹æ•°å­—é™ˆè¿°ï¼ˆå¦‚"å¢é•¿äº†50%"ã€"æœ‰1000ä¸‡ç”¨æˆ·"ï¼‰
        number_statements = re.findall(r'(\d+(?:\.\d+)?%|\d+(?:ä¸‡|äº¿|åƒ|ç™¾)?[\u4e00-\u9fa5]{0,3})',
                                      dialogue_content)

        # æ£€æµ‹ç»å¯¹æ€§æ–­è¨€ï¼ˆå¦‚"ä¸€å®š"ã€"å¿…ç„¶"ã€"æ°¸è¿œ"ï¼‰
        absolute_words = ['ä¸€å®š', 'å¿…ç„¶', 'ç»å¯¹', 'æ°¸è¿œ', 'ä»ä¸', 'æ€»æ˜¯', 'æ‰€æœ‰', 'æ²¡æœ‰ä»»ä½•']
        has_absolute = any(word in dialogue_content for word in absolute_words)

        if has_absolute:
            validation_result["warnings"].append("æ£€æµ‹åˆ°ç»å¯¹æ€§æ–­è¨€ï¼Œå»ºè®®ä¿æŒè°¨æ…æ€åº¦")
            validation_result["confidence"] *= 0.95

        # ç®€åŒ–ç‰ˆå†²çªæ£€æµ‹ï¼šæ£€æŸ¥æ˜¯å¦åŒ…å«ä¸çŸ¥è¯†åº“çŸ›ç›¾çš„å…³é”®è¯
        # ï¼ˆå®é™…åº”ç”¨ä¸­åº”ä½¿ç”¨è¯­ä¹‰ç›¸ä¼¼åº¦æˆ–ä¸“é—¨çš„äº‹å®æ ¡éªŒæ¨¡å‹ï¼‰
        knowledge_text = " ".join([
            point.get("content", "")
            for point in rag_context.get("knowledge_points", [])[:5]
        ])

        # æå–çŸ¥è¯†åº“ä¸­çš„æ•°å­—
        knowledge_numbers = re.findall(r'\d+(?:\.\d+)?', knowledge_text)

        # å¦‚æœå¯¹è¯æåˆ°çš„æ•°å­—è¿‡å¤šä¸”çŸ¥è¯†åº“ä¸­ä¹Ÿæœ‰æ•°å­—ï¼Œå¯èƒ½å­˜åœ¨å†²çªé£é™©
        if len(number_statements) > 3 and len(knowledge_numbers) > 0:
            validation_result["warnings"].append(
                f"æ£€æµ‹åˆ°{len(number_statements)}å¤„æ•°æ®é™ˆè¿°ï¼Œå»ºè®®ä¸çŸ¥è¯†åº“æ ¸å¯¹"
            )
            validation_result["confidence"] *= 0.9

        # æ£€æµ‹å¦å®šæ€§å†²çªï¼ˆå¦‚å¯¹è¯è¯´"ä¸ä¼š"ï¼Œä½†çŸ¥è¯†åº“è¯´"ä¼š"ï¼‰
        negative_patterns = ['ä¸ä¼š', 'ä¸èƒ½', 'æ²¡æœ‰', 'æ— æ³•', 'ä¸å¯èƒ½']
        dialogue_negatives = [word for word in negative_patterns if word in dialogue_content]

        if dialogue_negatives and len(knowledge_text) > 100:
            # ç®€åŒ–çš„å†²çªæ£€æµ‹ï¼ˆå®é™…åº”è¯¥ç”¨è¯­ä¹‰åˆ†æï¼‰
            validation_result["warnings"].append(
                f"æ£€æµ‹åˆ°å¦å®šæ€§è¡¨è¿°ï¼š{', '.join(dialogue_negatives[:3])}ï¼Œè¯·ç¡®ä¿ä¸çŸ¥è¯†åº“ä¸€è‡´"
            )

        # è®¡ç®—æœ€ç»ˆç½®ä¿¡åº¦
        final_confidence = validation_result["confidence"]
        if len(validation_result["warnings"]) > 2:
            validation_result["is_valid"] = False
            validation_result["conflicting_facts"].append(
                "å¤šå¤„æ½œåœ¨å†²çªï¼Œå»ºè®®äººå·¥å®¡æ ¸"
            )

        validation_result["confidence"] = round(final_confidence, 2)

        return validation_result

    def validate_content_safety(self, content: str, rag_context: Dict[str, Any] = None) -> tuple[bool, str]:
        """å†…å®¹å®‰å…¨éªŒè¯ï¼šç»¼åˆæ•æ„Ÿè¯æ£€æµ‹ã€äº‹å®æ€§æ£€æŸ¥å’Œé€»è¾‘ä¸€è‡´æ€§éªŒè¯

        Args:
            content: å¾…éªŒè¯çš„å†…å®¹
            rag_context: RAGçŸ¥è¯†ä¸Šä¸‹æ–‡ï¼ˆå¯é€‰ï¼‰

        Returns:
            (æ˜¯å¦é€šè¿‡éªŒè¯, è¯¦ç»†è¯´æ˜)
        """
        import re

        # 1. æ•æ„Ÿè¯æ£€æµ‹ï¼ˆåŸºç¡€æ•æ„Ÿè¯åˆ—è¡¨ - ç”Ÿäº§ç¯å¢ƒå»ºè®®ä½¿ç”¨ä¸“ä¸šæ•æ„Ÿè¯åº“ï¼‰
        sensitive_keywords = {
            'æ”¿æ²»æ•æ„Ÿ': ['æ”¿æ²»', 'æ”¿åºœ', 'é¢†å¯¼äºº', 'å…š', 'æ”¿ç­–'],  # ç¤ºä¾‹ï¼Œå®é™…åº”æ›´å…¨é¢
            'æš´åŠ›': ['æš´åŠ›', 'æ€äºº', 'ä¼¤å®³', 'æ”»å‡»', 'æš´æ‰“'],
            'è‰²æƒ…': ['è‰²æƒ…', 'æ€§', 'è£¸ä½“'],  # ç¤ºä¾‹å…³é”®è¯
            'æ­§è§†': ['æ­§è§†', 'ç§æ—', 'æ€§åˆ«æ­§è§†', 'åœ°åŸŸæ­§è§†'],
            'è°£è¨€': ['æœªç»è¯å®', 'æ®è¯´', 'å¬è¯´', 'ä¼ é—»'],
            'å•†ä¸šé£é™©': ['æŠ•èµ„å»ºè®®', 'ä¿è¯èµšé’±', 'ç¨³èµšä¸èµ”', 'å¿…æ¶¨']
        }

        detected_issues = []

        # æ£€æµ‹æ•æ„Ÿè¯ï¼ˆç”Ÿäº§ç¯å¢ƒåº”ä½¿ç”¨æ›´å¤æ‚çš„ç®—æ³•ï¼Œå¦‚DFAæˆ–ACè‡ªåŠ¨æœºï¼‰
        for category, keywords in sensitive_keywords.items():
            for keyword in keywords:
                if keyword in content:
                    detected_issues.append(f"æ£€æµ‹åˆ°{category}ç›¸å…³å†…å®¹ï¼š{keyword}")

        # 2. äº‹å®æ€§æ£€æŸ¥ï¼ˆç»“åˆRAGï¼‰
        if rag_context:
            fact_check_result = self._validate_against_knowledge(content, rag_context)
            if not fact_check_result["is_valid"]:
                detected_issues.append(f"äº‹å®æ€§æ ¡éªŒæœªé€šè¿‡ï¼š{', '.join(fact_check_result['warnings'])}")
            elif fact_check_result["confidence"] < 0.7:
                detected_issues.append(f"äº‹å®å¯ä¿¡åº¦åä½ ({fact_check_result['confidence']})")

        # 3. é€»è¾‘ä¸€è‡´æ€§éªŒè¯
        # æ£€æµ‹è‡ªç›¸çŸ›ç›¾çš„è¡¨è¿°ï¼ˆç®€åŒ–ç‰ˆï¼‰
        contradiction_patterns = [
            (r'(ä¸ä¼š|ä¸èƒ½|æ²¡æœ‰|æ— æ³•).{0,20}(ä½†æ˜¯|ç„¶è€Œ|å¯æ˜¯).{0,20}(ä¼š|èƒ½|æœ‰|å¯ä»¥)', 'æ£€æµ‹åˆ°å¯èƒ½çš„é€»è¾‘çŸ›ç›¾ï¼šå‰åè¡¨è¿°ä¸ä¸€è‡´'),
            (r'(ä¸€å®š|å¿…ç„¶|è‚¯å®š).{0,20}(å¯èƒ½|ä¹Ÿè®¸|æˆ–è®¸)', 'æ£€æµ‹åˆ°é€»è¾‘å†²çªï¼šç¡®å®šæ€§ä¸ä¸ç¡®å®šæ€§æ··ç”¨'),
            (r'(å¢åŠ |ä¸Šå‡|æé«˜).{0,20}(å‡å°‘|ä¸‹é™|é™ä½)', 'æ£€æµ‹åˆ°æ•°å€¼çŸ›ç›¾ï¼šå¢å‡è¡¨è¿°å†²çª'),
        ]

        for pattern, message in contradiction_patterns:
            if re.search(pattern, content):
                detected_issues.append(message)

        # æ£€æµ‹è¿‡äºå¤¸å¼ çš„é™ˆè¿°
        exaggeration_keywords = ['100%', 'å®Œå…¨', 'ç»å¯¹', 'æ‰€æœ‰', 'ä»ä¸', 'æ°¸è¿œ', 'å¿…ç„¶']
        exaggeration_count = sum(1 for keyword in exaggeration_keywords if keyword in content)
        if exaggeration_count > 2:
            detected_issues.append(f"æ£€æµ‹åˆ°è¿‡å¤šç»å¯¹åŒ–è¡¨è¿°ï¼ˆ{exaggeration_count}å¤„ï¼‰ï¼Œå¯èƒ½ç¼ºä¹å®¢è§‚æ€§")

        # åˆ¤æ–­æ˜¯å¦é€šè¿‡
        is_safe = len(detected_issues) == 0

        if is_safe:
            return True, "å†…å®¹å®‰å…¨éªŒè¯é€šè¿‡"
        else:
            return False, "å†…å®¹å®‰å…¨é—®é¢˜ï¼š" + "; ".join(detected_issues)

    async def _plan_dialogue_structure(self, form: PodcastCustomForm,
                                     rag_context: Dict[str, Any] = None,
                                     analysis_result: Dict[str, Any] = None) -> Dict[str, Any]:
        """ç»“æ„åŒ–å†…å®¹ç”Ÿæˆ - ç¬¬ä¸€é˜¶æ®µï¼šè§„åˆ’å¯¹è¯ç»“æ„

        ç”Ÿæˆæ’­å®¢å¯¹è¯çš„æ•´ä½“ç»“æ„æ¡†æ¶ï¼ŒåŒ…æ‹¬ï¼š
        - å„ä¸ªè®¨è®ºé˜¶æ®µçš„åˆ’åˆ†
        - æ¯ä¸ªé˜¶æ®µçš„ç›®æ ‡ã€å­—æ•°ã€å‚ä¸è§’è‰²
        - å…³é”®è®¨è®ºç‚¹å’Œè½¬æŠ˜ç‚¹

        Args:
            form: æ’­å®¢å®šåˆ¶è¡¨å•
            rag_context: RAGçŸ¥è¯†ä¸Šä¸‹æ–‡
            analysis_result: Geminiç´ æåˆ†æç»“æœ

        Returns:
            ç»“æ„åŒ–çš„å¯¹è¯è§„åˆ’å­—å…¸
        """
        # ç”Ÿæˆç¼“å­˜é”®
        cache_key = self._get_cache_key(
            "structure",
            form.topic,
            form.target_duration,
            len(form.characters),
            form.atmosphere.value
        )

        # å°è¯•ä»ç¼“å­˜è·å–
        cached_structure = self._get_from_cache(self._structure_cache, cache_key)
        if cached_structure:
            print(f"[ç»“æ„è§„åˆ’] ä½¿ç”¨ç¼“å­˜çš„ç»“æ„è§„åˆ’")
            return cached_structure

        print(f"[ç»“æ„è§„åˆ’] å¼€å§‹ç”Ÿæˆå¯¹è¯ç»“æ„...")

        # è®¡ç®—æ€»ç›®æ ‡å­—æ•°
        target_word_count = self.estimate_target_word_count(form.target_duration)

        # æ„å»ºè§’è‰²ä¿¡æ¯
        characters_info = [char.name for char in form.characters]
        host_name = characters_info[0] if characters_info else "ä¸»æŒäºº"

        # æ„å»ºçŸ¥è¯†è¦ç‚¹ï¼ˆå¦‚æœæœ‰ï¼‰
        knowledge_highlights = []
        if rag_context and rag_context.get("knowledge_points"):
            knowledge_highlights = [
                point.get("content", "")[:100] for point in rag_context["knowledge_points"][:3]
            ]

        # æ„å»ºç´ æè¦ç‚¹ï¼ˆå¦‚æœæœ‰ï¼‰
        material_highlights = []
        if analysis_result:
            if analysis_result.get("main_thesis"):
                material_highlights.append(f"æ ¸å¿ƒè§‚ç‚¹ï¼š{analysis_result['main_thesis']}")
            if analysis_result.get("key_arguments"):
                material_highlights.extend(analysis_result["key_arguments"][:2])

        # ç”Ÿæˆç»“æ„è§„åˆ’Prompt
        structure_prompt = f"""# ä»»åŠ¡ï¼šä¸ºæ’­å®¢ç”Ÿæˆç»“æ„åŒ–å¯¹è¯è§„åˆ’

## æ’­å®¢ä¿¡æ¯
- ä¸»é¢˜ï¼š{form.topic}
- æ—¶é•¿ç›®æ ‡ï¼š{form.target_duration} ({target_word_count}å­—å·¦å³)
- æ°›å›´ï¼š{form.atmosphere.value}
- ä¸»æŒäººï¼š{host_name}
- å˜‰å®¾ï¼š{', '.join(characters_info[1:])}

## å¯ç”¨ç´ æ
{chr(10).join(['- ' + h for h in knowledge_highlights + material_highlights]) if knowledge_highlights or material_highlights else 'æš‚æ— é¢å¤–ç´ æ'}

## ä»»åŠ¡è¦æ±‚
è¯·è®¾è®¡ä¸€ä¸ª**ç»“æ„åŒ–çš„å¯¹è¯æµç¨‹**ï¼Œå°†æ•´ä¸ªæ’­å®¢åˆ†ä¸º5-7ä¸ªé˜¶æ®µï¼Œæ¯ä¸ªé˜¶æ®µåŒ…å«ï¼š
1. é˜¶æ®µåç§°å’Œç›®æ ‡
2. é¢„è®¡å­—æ•°ï¼ˆæ€»è®¡{target_word_count}å­—ï¼‰
3. è®¨è®ºé‡ç‚¹/å…³é”®é—®é¢˜
4. å‚ä¸è§’è‰²å’Œäº’åŠ¨æ–¹å¼

## è¾“å‡ºæ ¼å¼ï¼ˆJSONï¼‰
{{
  "total_target_words": {target_word_count},
  "total_stages": 6,
  "stages": [
    {{
      "stage_number": 1,
      "stage_name": "å¼€åœºæ¬¢è¿",
      "target_words": 150,
      "objectives": ["ä¸»æŒäººè‡ªæˆ‘ä»‹ç»", "ä»‹ç»å˜‰å®¾", "å¼•å…¥è¯é¢˜"],
      "discussion_points": ["ä»Šå¤©çš„ä¸»é¢˜æ˜¯ä»€ä¹ˆ", "ä¸ºä»€ä¹ˆé‡è¦"],
      "participants": ["{host_name}"],
      "interaction_style": "ä¸»æŒäººç‹¬ç™½+ç®€çŸ­å˜‰å®¾å›åº”"
    }},
    {{
      "stage_number": 2,
      "stage_name": "è¯é¢˜å¼•å…¥",
      "target_words": 200,
      "objectives": ["æå‡ºæ ¸å¿ƒé—®é¢˜", "å˜‰å®¾è¡¨æ˜ç«‹åœº"],
      "discussion_points": ["æ ¸å¿ƒé—®é¢˜æ˜¯ä»€ä¹ˆ", "å„è‡ªçš„åˆæ­¥è§‚ç‚¹"],
      "participants": ["{host_name}", "{characters_info[1] if len(characters_info) > 1 else 'å˜‰å®¾'}"],
      "interaction_style": "é—®ç­”äº’åŠ¨"
    }},
    {{
      "stage_number": 3,
      "stage_name": "æ·±å…¥è®¨è®º",
      "target_words": 300,
      "objectives": ["æ·±å…¥é˜è¿°å„è‡ªè§‚ç‚¹", "æä¾›æ¡ˆä¾‹æ”¯æ’‘"],
      "discussion_points": ["å…·ä½“æ¡ˆä¾‹åˆ†æ", "æ•°æ®æˆ–äº‹å®æ”¯æ’‘"],
      "participants": ["{', '.join(characters_info)}"],
      "interaction_style": "è½®æµé˜è¿°+ä¸»æŒäººè¿½é—®"
    }},
    {{
      "stage_number": 4,
      "stage_name": "è§‚ç‚¹ç¢°æ’",
      "target_words": 250,
      "objectives": ["ä¸åŒè§‚ç‚¹äº¤é”‹", "è¾©è®ºå’Œå›åº”"],
      "discussion_points": ["äº‰è®®ç„¦ç‚¹", "å„æ–¹ç«‹åœºå·®å¼‚"],
      "participants": ["{', '.join(characters_info)}"],
      "interaction_style": "è¾©è®ºå¼äº’åŠ¨"
    }},
    {{
      "stage_number": 5,
      "stage_name": "æ€»ç»“ä¸å±•æœ›",
      "target_words": 150,
      "objectives": ["æ€»ç»“å…³é”®è§‚ç‚¹", "æœªæ¥å±•æœ›"],
      "discussion_points": ["æ ¸å¿ƒç»“è®º", "æœªæ¥è¶‹åŠ¿"],
      "participants": ["{host_name}"],
      "interaction_style": "ä¸»æŒäººæ€»ç»“"
    }},
    {{
      "stage_number": 6,
      "stage_name": "è‡´è°¢ç»“æŸ",
      "target_words": 100,
      "objectives": ["æ„Ÿè°¢å˜‰å®¾", "æ„Ÿè°¢å¬ä¼—", "é“åˆ«"],
      "discussion_points": ["è‡´è°¢", "é¢„å‘Šä¸‹æœŸ"],
      "participants": ["{', '.join(characters_info)}"],
      "interaction_style": "é›†ä½“é“åˆ«"
    }}
  ],
  "key_transitions": [
    "ä»å¼•å…¥åˆ°æ·±å…¥ï¼šä¸»æŒäººæå‡ºå…³é”®è¿½é—®",
    "ä»è®¨è®ºåˆ°ç¢°æ’ï¼šå¼•å…¥äº‰è®®è¯é¢˜æˆ–åå¯¹è§‚ç‚¹",
    "ä»ç¢°æ’åˆ°æ€»ç»“ï¼šä¸»æŒäººæ¢³ç†å…±è¯†ä¸åˆ†æ­§"
  ],
  "quality_checkpoints": [
    "æ¯ä¸ªé˜¶æ®µæ˜¯å¦æœ‰å…·ä½“æ¡ˆä¾‹æˆ–æ•°æ®",
    "å˜‰å®¾ä¹‹é—´æ˜¯å¦æœ‰çœŸå®äº’åŠ¨",
    "æ˜¯å¦é¿å…ç©ºæ´çš„å¥—è¯"
  ]
}}

**æ³¨æ„**ï¼š
- ç›´æ¥è¾“å‡ºJSONï¼Œä¸è¦ç”¨```åŒ…è£¹
- stagesæ•°ç»„é•¿åº¦ä¸º5-7ä¸ª
- æ¯ä¸ªé˜¶æ®µtarget_wordsæ€»å’Œåº”çº¦ç­‰äº{target_word_count}
- discussion_pointsè¦å…·ä½“ä¸”ä¸ä¸»é¢˜ç›¸å…³

ç°åœ¨ç”Ÿæˆç»“æ„è§„åˆ’ï¼š"""

        try:
            # è°ƒç”¨LLMç”Ÿæˆç»“æ„è§„åˆ’
            response = await self.deepseek_client.chat.completions.create(
                model=settings.deepseek_model,
                messages=[{"role": "user", "content": structure_prompt}],
                temperature=0.5  # è¾ƒä½æ¸©åº¦ç¡®ä¿ç»“æ„åˆç†
            )

            result_text = response.choices[0].message.content.strip()

            # æ¸…ç†JSON
            if "```json" in result_text:
                result_text = result_text.split("```json")[1].split("```")[0].strip()
            elif "```" in result_text:
                result_text = result_text.split("```")[1].split("```")[0].strip()

            # è§£æç»“æ„è§„åˆ’
            structure_plan = json.loads(result_text)

            print(f"[ç»“æ„è§„åˆ’] ç”ŸæˆæˆåŠŸï¼Œå…±{structure_plan.get('total_stages', 0)}ä¸ªé˜¶æ®µ")
            for stage in structure_plan.get('stages', [])[:3]:
                print(f"  é˜¶æ®µ{stage['stage_number']}: {stage['stage_name']} ({stage['target_words']}å­—)")

            # ç¼“å­˜ç»“æœ
            self._set_to_cache(self._structure_cache, cache_key, structure_plan)

            return structure_plan

        except Exception as e:
            print(f"[ç»“æ„è§„åˆ’] ç”Ÿæˆå¤±è´¥: {str(e)}")
            # è¿”å›é»˜è®¤ç»“æ„
            fallback_structure = self._get_fallback_structure(target_word_count, characters_info)
            # ç¼“å­˜é»˜è®¤ç»“æ„
            self._set_to_cache(self._structure_cache, cache_key, fallback_structure)
            return fallback_structure

    def _get_fallback_structure(self, target_word_count: int, characters: List[str]) -> Dict[str, Any]:
        """ç”Ÿæˆé»˜è®¤çš„å¯¹è¯ç»“æ„ï¼ˆå½“LLMè§„åˆ’å¤±è´¥æ—¶ï¼‰"""
        host_name = characters[0] if characters else "ä¸»æŒäºº"

        return {
            "total_target_words": target_word_count,
            "total_stages": 6,
            "stages": [
                {
                    "stage_number": 1,
                    "stage_name": "å¼€åœºæ¬¢è¿",
                    "target_words": int(target_word_count * 0.15),
                    "objectives": ["ä¸»æŒäººå¼€åœº", "ä»‹ç»å˜‰å®¾"],
                    "discussion_points": ["ä»Šå¤©çš„è¯é¢˜ä»‹ç»"],
                    "participants": [host_name],
                    "interaction_style": "ä¸»æŒäººç‹¬ç™½"
                },
                {
                    "stage_number": 2,
                    "stage_name": "è¯é¢˜å¼•å…¥",
                    "target_words": int(target_word_count * 0.20),
                    "objectives": ["å¼•å…¥æ ¸å¿ƒè¯é¢˜", "å˜‰å®¾è¡¨æ€"],
                    "discussion_points": ["æ ¸å¿ƒé—®é¢˜é˜è¿°"],
                    "participants": characters,
                    "interaction_style": "é—®ç­”äº’åŠ¨"
                },
                {
                    "stage_number": 3,
                    "stage_name": "æ·±å…¥è®¨è®º",
                    "target_words": int(target_word_count * 0.30),
                    "objectives": ["æ·±å…¥é˜è¿°è§‚ç‚¹"],
                    "discussion_points": ["æ¡ˆä¾‹åˆ†æ", "æ•°æ®æ”¯æ’‘"],
                    "participants": characters,
                    "interaction_style": "è½®æµå‘è¨€"
                },
                {
                    "stage_number": 4,
                    "stage_name": "è§‚ç‚¹äº¤æµ",
                    "target_words": int(target_word_count * 0.20),
                    "objectives": ["è§‚ç‚¹ç¢°æ’"],
                    "discussion_points": ["ä¸åŒè§†è§’å¯¹æ¯”"],
                    "participants": characters,
                    "interaction_style": "äº’åŠ¨è¾©è®º"
                },
                {
                    "stage_number": 5,
                    "stage_name": "æ€»ç»“",
                    "target_words": int(target_word_count * 0.10),
                    "objectives": ["æ€»ç»“è¦ç‚¹"],
                    "discussion_points": ["æ ¸å¿ƒç»“è®º"],
                    "participants": [host_name],
                    "interaction_style": "ä¸»æŒäººæ€»ç»“"
                },
                {
                    "stage_number": 6,
                    "stage_name": "ç»“æŸ",
                    "target_words": int(target_word_count * 0.05),
                    "objectives": ["è‡´è°¢é“åˆ«"],
                    "discussion_points": ["æ„Ÿè°¢æ”¶å¬"],
                    "participants": characters,
                    "interaction_style": "é›†ä½“é“åˆ«"
                }
            ],
            "key_transitions": ["å¼•å…¥è¯é¢˜", "æ·±å…¥è®¨è®º", "æ€»ç»“æ”¶å°¾"],
            "quality_checkpoints": ["æ˜¯å¦æœ‰å…·ä½“æ¡ˆä¾‹", "æ˜¯å¦æœ‰çœŸå®äº’åŠ¨"],
            "_fallback": True
        }

    async def _generate_stage_content(self, stage_info: Dict[str, Any],
                                     form: PodcastCustomForm,
                                     rag_context: Dict[str, Any] = None) -> List[ScriptDialogue]:
        """ç»“æ„åŒ–å†…å®¹ç”Ÿæˆ - ç¬¬äºŒé˜¶æ®µï¼šåŸºäºç»“æ„è§„åˆ’ç”Ÿæˆå…·ä½“å¯¹è¯å†…å®¹

        Args:
            stage_info: å½“å‰é˜¶æ®µçš„ç»“æ„ä¿¡æ¯
            form: æ’­å®¢å®šåˆ¶è¡¨å•
            rag_context: RAGçŸ¥è¯†ä¸Šä¸‹æ–‡

        Returns:
            ç”Ÿæˆçš„å¯¹è¯åˆ—è¡¨
        """
        print(f"[é˜¶æ®µç”Ÿæˆ] å¼€å§‹ç”Ÿæˆé˜¶æ®µ{stage_info['stage_number']}: {stage_info['stage_name']}")

        # æ„å»ºè§’è‰²äººè®¾ä¿¡æ¯
        characters_personas = []
        for char in form.characters:
            if char.name in stage_info.get('participants', []):
                persona = self.generate_character_persona_prompt(char)
                characters_personas.append(persona)

        # æ„å»ºå·²æœ‰å¯¹è¯ä¸Šä¸‹æ–‡ï¼ˆæœ€è¿‘3è½®ï¼‰
        recent_history = ""
        if self.conversation_history:
            recent_dialogues = self.conversation_history[-3:]
            recent_history = "\n".join([
                f"{d.character_name}ï¼š{d.content[:50]}..."
                for d in recent_dialogues
            ])

        # æ„å»ºRAGçŸ¥è¯†å‚è€ƒï¼ˆå¦‚æœæœ‰ï¼‰
        rag_section = ""
        if rag_context and rag_context.get("knowledge_points"):
            knowledge_items = []
            for point in rag_context["knowledge_points"][:2]:
                confidence = self._calculate_knowledge_confidence(point)
                marker = "ğŸŸ¢" if confidence >= 0.8 else "ğŸŸ¡"
                knowledge_items.append(f"{marker} {point['content'][:150]}...")

            rag_section = f"""
## ğŸ“š å¯å‚è€ƒçŸ¥è¯†ï¼ˆè‡ªç„¶èå…¥ï¼‰
{chr(10).join(knowledge_items)}
"""

        # ç”Ÿæˆæœ¬é˜¶æ®µçš„å¯¹è¯Prompt
        stage_prompt = f"""# ä»»åŠ¡ï¼šç”Ÿæˆæ’­å®¢ç¬¬{stage_info['stage_number']}é˜¶æ®µçš„å¯¹è¯å†…å®¹

## é˜¶æ®µç›®æ ‡
- **é˜¶æ®µåç§°**ï¼š{stage_info['stage_name']}
- **ç›®æ ‡å­—æ•°**ï¼š{stage_info['target_words']}å­—
- **æ ¸å¿ƒç›®æ ‡**ï¼š{', '.join(stage_info['objectives'])}
- **è®¨è®ºé‡ç‚¹**ï¼š{', '.join(stage_info['discussion_points'])}
- **äº’åŠ¨æ–¹å¼**ï¼š{stage_info['interaction_style']}

## æ’­å®¢ä¿¡æ¯
- ä¸»é¢˜ï¼š{form.topic}
- æ°›å›´ï¼š{form.atmosphere.value}

## å‚ä¸è§’è‰²äººè®¾
{chr(10).join(characters_personas)}

## å·²æœ‰å¯¹è¯ï¼ˆä¸Šä¸‹æ–‡ï¼‰
{recent_history if recent_history else "è¿™æ˜¯æ’­å®¢çš„ç¬¬ä¸€é˜¶æ®µ"}

{rag_section}

## ğŸ­ å¯¹è¯ç”Ÿæˆè¦æ±‚

**ã€å¿…é¡»éµå®ˆçš„æ ¸å¿ƒå‡†åˆ™ã€‘**
1. **è§‚ç‚¹å¿…é¡»é…æ¡ˆä¾‹**ï¼šæ¯ä¸ªè§‚ç‚¹éƒ½è¦æœ‰å…·ä½“æ¡ˆä¾‹ã€æ•°æ®æˆ–æ•…äº‹æ”¯æ’‘
2. **çœŸå®å£è¯­åŒ–**ï¼šç”¨"å…¶å®"ã€"ä½ çœ‹"ã€"è¯´å®è¯"ç­‰å£è¯­è¯ï¼Œæœ‰åœé¡¿æ„Ÿ
3. **äº’åŠ¨å›åº”**ï¼šè§’è‰²ä¹‹é—´è¦çœŸå®äº’åŠ¨ï¼Œè¿½é—®ã€è´¨ç–‘ã€è¡¥å……
4. **é¿å…ç©ºæ´å¥—è¯**ï¼šç¦æ­¢"éå¸¸ç²¾å½©"ã€"å¾ˆæœ‰é“ç†"ç­‰æ•·è¡è¯æœ¯

**ã€å­—æ•°æ§åˆ¶ã€‘**
- ç”Ÿæˆ{max(2, stage_info['target_words'] // 80)}æ®µå¯¹è¯
- æ¯æ®µ60-100å­—
- æ€»å­—æ•°çº¦{stage_info['target_words']}å­—

## âš ï¸ è¾“å‡ºæ ¼å¼ï¼ˆJSONï¼‰

{{
  "dialogues": [
    {{
      "character_name": "è§’è‰²å",
      "content": "å¯¹è¯å†…å®¹ï¼ˆçº¯æ–‡æœ¬ï¼Œä¸å«æƒ…ç»ªæ ‡æ³¨ï¼‰",
      "emotion": "æƒ…ç»ªè¯"
    }}
  ]
}}

**æ³¨æ„**ï¼š
- ç›´æ¥è¾“å‡ºJSONï¼Œä¸è¦ç”¨```åŒ…è£¹
- contentå¿…é¡»æ˜¯çº¯æ–‡æœ¬ï¼Œä¸å«æ‹¬å·æ ‡æ³¨
- ç”Ÿæˆçš„å¯¹è¯è¦ç¬¦åˆé˜¶æ®µç›®æ ‡å’Œå­—æ•°è¦æ±‚

ç°åœ¨ç”Ÿæˆæœ¬é˜¶æ®µå¯¹è¯ï¼š"""

        try:
            # è°ƒç”¨LLMç”Ÿæˆæœ¬é˜¶æ®µå†…å®¹
            response = await self.deepseek_client.chat.completions.create(
                model=settings.deepseek_model,
                messages=[{"role": "user", "content": stage_prompt}],
                temperature=0.7
            )

            result_text = response.choices[0].message.content.strip()

            # æ¸…ç†JSON
            if "```json" in result_text:
                result_text = result_text.split("```json")[1].split("```")[0].strip()
            elif "```" in result_text:
                result_text = result_text.split("```")[1].split("```")[0].strip()

            result_text = result_text.replace('\n', '\\n').replace('\r', '\\r').replace('\t', '\\t')
            result_text = re.sub(r'\\n\s*\\n', '\\n', result_text)

            # è§£æJSON
            stage_data = json.loads(result_text)

            # è½¬æ¢ä¸ºå¯¹è¯å¯¹è±¡åˆ—è¡¨
            dialogues = []
            for dialogue_data in stage_data["dialogues"]:
                # æ¸…ç†å†…å®¹
                original_content = dialogue_data["content"]
                cleaned_content = clean_for_tts(original_content, emotion=dialogue_data.get("emotion"))

                # å†…å®¹å®‰å…¨æ£€æŸ¥
                is_safe, safety_message = self.validate_content_safety(cleaned_content, rag_context)
                if not is_safe:
                    print(f"[é˜¶æ®µç”Ÿæˆ] âš ï¸ å†…å®¹å®‰å…¨é—®é¢˜: {safety_message}")
                    # ç”Ÿäº§ç¯å¢ƒå¯ä»¥é€‰æ‹©è·³è¿‡
                    # continue

                dialogue = ScriptDialogue(
                    character_name=dialogue_data["character_name"],
                    content=cleaned_content,
                    emotion=dialogue_data.get("emotion")
                )
                dialogues.append(dialogue)

            word_count = sum(len(d.content) for d in dialogues)
            print(f"[é˜¶æ®µç”Ÿæˆ] é˜¶æ®µ{stage_info['stage_number']}ç”Ÿæˆå®Œæˆï¼Œå…±{len(dialogues)}æ®µå¯¹è¯ï¼Œ{word_count}å­—")

            return dialogues

        except Exception as e:
            print(f"[é˜¶æ®µç”Ÿæˆ] ç”Ÿæˆå¤±è´¥: {str(e)}")
            return []

    def _create_fallback_client(self):
        """åˆ›å»ºå›é€€å®¢æˆ·ç«¯ï¼ˆç”¨äºæ¼”ç¤ºå’Œæµ‹è¯•ï¼‰"""
        return FallbackClient()

    def estimate_target_word_count(self, duration_str: str) -> int:
        """æ ¹æ®ç›®æ ‡æ—¶é•¿ä¼°ç®—ç›®æ ‡å­—æ•°"""
        # æå–æ•°å­—
        numbers = re.findall(r'\d+', duration_str)
        if not numbers:
            return 800  # é»˜è®¤å­—æ•°

        minutes = int(numbers[0])
        # ä¸€èˆ¬æ’­å®¢è¯­é€Ÿçº¦ä¸ºæ¯åˆ†é’Ÿ150-200å­—
        return minutes * 175

    def initialize_generation_state(self, form: PodcastCustomForm):
        """åˆå§‹åŒ–ç”ŸæˆçŠ¶æ€"""
        self.conversation_history = []
        self.characters_list = [char.name for char in form.characters]
        self.current_speaker_index = 0
        self.target_word_count = self.estimate_target_word_count(form.target_duration)
        self.current_word_count = 0

    def get_next_speaker(self) -> str:
        """æ™ºèƒ½å†³å®šä¸‹ä¸€ä½å‘è¨€è€…"""
        # ç®€å•è½®æµç­–ç•¥ï¼Œåç»­å¯ä»¥æ”¹ä¸ºAIå†³å®š
        speaker = self.characters_list[self.current_speaker_index]
        self.current_speaker_index = (self.current_speaker_index + 1) % len(self.characters_list)
        return speaker

    def should_terminate(self) -> bool:
        """åˆ¤æ–­æ˜¯å¦åº”è¯¥ç»ˆæ­¢ç”Ÿæˆ"""
        # æ£€æŸ¥å­—æ•°æ˜¯å¦è¾¾åˆ°ç›®æ ‡
        if self.current_word_count >= self.target_word_count:
            return True

        # æ£€æŸ¥æ˜¯å¦æœ‰æ˜ç¡®çš„ç»“æŸæ ‡å¿—
        if self.conversation_history:
            last_content = self.conversation_history[-1].content
            end_keywords = ["æ„Ÿè°¢å¤§å®¶æ”¶å¬", "ä»Šå¤©çš„æ’­å®¢", "æˆ‘ä»¬ä¸‹æœŸå†è§", "è°¢è°¢æ”¶å¬"]
            if any(keyword in last_content for keyword in end_keywords):
                return True

        return False

    def check_content_repetition(self, new_content: str, window_size: int = 3) -> bool:
        """æ£€æŸ¥æ–°å†…å®¹æ˜¯å¦ä¸æœ€è¿‘çš„å¯¹è¯é‡å¤

        Args:
            new_content: æ–°ç”Ÿæˆçš„å†…å®¹
            window_size: æ£€æŸ¥æœ€è¿‘å‡ è½®å¯¹è¯

        Returns:
            Trueè¡¨ç¤ºæœ‰é‡å¤ï¼ŒFalseè¡¨ç¤ºæ— é‡å¤
        """
        if not self.conversation_history:
            return False

        # è·å–æœ€è¿‘å‡ è½®å¯¹è¯
        recent_dialogues = self.conversation_history[-window_size:]

        # è®¡ç®—ç›¸ä¼¼åº¦ï¼ˆç®€å•çš„å­—ç¬¦ä¸²åŒ…å«æ£€æŸ¥ï¼‰
        new_content_clean = new_content.strip().lower()

        for dialogue in recent_dialogues:
            old_content_clean = dialogue.content.strip().lower()

            # å¦‚æœæ–°å†…å®¹ä¸æ—§å†…å®¹è¿‡äºç›¸ä¼¼ï¼ˆè¶…è¿‡50%é‡å¤ï¼‰
            if len(new_content_clean) > 20:  # åªæ£€æŸ¥è¶³å¤Ÿé•¿çš„å†…å®¹
                overlap = sum(1 for i in range(len(new_content_clean)-10)
                            if new_content_clean[i:i+10] in old_content_clean)
                similarity = overlap / (len(new_content_clean) - 10) if len(new_content_clean) > 10 else 0

                if similarity > 0.5:  # 50%ä»¥ä¸Šç›¸ä¼¼åº¦è®¤ä¸ºé‡å¤
                    return True

        return False

    def count_words_in_history(self) -> int:
        """ç»Ÿè®¡å¯¹è¯å†å²ä¸­çš„å­—æ•°"""
        return sum(len(dialogue.content) for dialogue in self.conversation_history)

    def generate_character_persona_prompt(self, char) -> str:
        """æ ¹æ®ä¸‰å±‚è§’è‰²æ„å»ºæ³•ç”Ÿæˆè¯¦ç»†çš„äººè®¾æè¿°"""

        # ç¬¬ä¸€å±‚ï¼šæ ¸å¿ƒèº«ä»½ï¼ˆå¿…å¡«ï¼‰
        persona_text = f"**{char.name}**ï¼š{char.persona}ï¼Œè§‚ç‚¹æ˜¯{char.core_viewpoint}"

        # ç¬¬äºŒå±‚ï¼šæ·±åº¦æ„å»ºï¼ˆå¯é€‰ï¼‰
        depth_parts = []

        # èƒŒæ™¯æ•…äº‹
        if char.backstory or char.backstory_impact:
            depth_parts.append("\n  - èƒŒæ™¯ï¼š")
            if char.backstory:
                depth_parts.append(f"{char.backstory}")
            if char.backstory_impact:
                depth_parts.append(f"ï¼ˆ{char.backstory_impact}ï¼‰")

        # æ²Ÿé€šé£æ ¼
        communication_style = []
        if char.language_habits:
            communication_style.append(f"è¯­è¨€ä¹ æƒ¯ï¼š{char.language_habits}")
        if char.catchphrases:
            communication_style.append(f"å£å¤´ç¦…ï¼š{char.catchphrases}")
        if char.speech_pace:
            communication_style.append(f"è¯­é€Ÿç‰¹ç‚¹ï¼š{char.speech_pace}")

        if communication_style:
            depth_parts.append("\n  - æ²Ÿé€šé£æ ¼ï¼š" + "ï¼›".join(communication_style))

        # å†…åœ¨ä»·å€¼è§‚ä¸çŸ›ç›¾
        if char.core_values:
            depth_parts.append(f"\n  - ä»·å€¼è§‚ï¼š{char.core_values}")
        if char.inner_contradictions:
            depth_parts.append(f"\n  - å†…åœ¨çŸ›ç›¾ï¼š{char.inner_contradictions}")

        # éšè—åŠ¨æœº
        if char.hidden_motivation:
            depth_parts.append(f"\n  - éšè—åŠ¨æœºï¼š{char.hidden_motivation}")

        # ç»„åˆå®Œæ•´æè¿°
        if depth_parts:
            persona_text += "".join(depth_parts)

        return persona_text

    def generate_initial_prompt(self, form: PodcastCustomForm, analysis_result: Dict[str, Any] = None,
                               rag_context: Dict[str, Any] = None) -> str:
        """ç”Ÿæˆåˆå§‹åŒ–Prompt - æ•´åˆä¸‰å±‚è§’è‰²æ„å»ºæ³•ï¼Œä¼˜åŒ–æ’­å®¢ç»“æ„"""
        # ä½¿ç”¨æ–°çš„è§’è‰²äººè®¾ç”Ÿæˆæ–¹æ³•
        characters_info = []
        host_name = None
        guest_names = []

        for char in form.characters:
            char_desc = f"* {self.generate_character_persona_prompt(char)}"
            characters_info.append(char_desc)

            # è¯†åˆ«ä¸»æŒäººï¼ˆç¬¬ä¸€ä¸ªè§’è‰²é»˜è®¤ä¸ºä¸»æŒäººï¼‰
            if not host_name:
                host_name = char.name
            else:
                guest_names.append(char.name)

        characters_str = "\n".join(characters_info)

        # å¦‚æœæ²¡æœ‰æ˜ç¡®çš„ä¸»æŒäººï¼Œä½¿ç”¨ç¬¬ä¸€ä¸ªè§’è‰²
        if not host_name:
            host_name = self.characters_list[0] if self.characters_list else "ä¸»æŒäºº"

        # æ„å»ºå˜‰å®¾åˆ—è¡¨æ–‡æœ¬
        guests_intro = "ã€".join(guest_names) if guest_names else "å˜‰å®¾"

        # æ„å»ºçŸ¥è¯†å‚è€ƒéƒ¨åˆ†
        knowledge_section = ""
        if rag_context and rag_context.get("knowledge_points"):
            knowledge_points = rag_context["knowledge_points"][:2]
            knowledge_texts = [f"- {point['content'][:150]}..." for point in knowledge_points]
            knowledge_section = f"\n### å¯å‚è€ƒçš„çŸ¥è¯†\n{chr(10).join(knowledge_texts)}\n"

        analysis_section = ""
        if analysis_result and analysis_result.get('main_thesis'):
            analysis_section = f"\n### ç´ æè¦ç‚¹\næ ¸å¿ƒè§‚ç‚¹ï¼š{analysis_result['main_thesis']}\n"

        return f"""ä½ æ˜¯ä¸“ä¸šæ’­å®¢å‰§æœ¬ä½œå®¶ã€‚è¯·ä¸ºä»¥ä¸‹æ’­å®¢ç”Ÿæˆ**å®Œæ•´çš„å¼€åœºéƒ¨åˆ†**ï¼ŒåŒ…æ‹¬ä¸»æŒäººå¼€åœºã€ä»‹ç»å˜‰å®¾å’Œå¼•å…¥è¯é¢˜ã€‚

## åŸºæœ¬ä¿¡æ¯
ä¸»é¢˜ï¼š{form.topic}
æ°›å›´ï¼š{form.atmosphere.value}
ä¸»æŒäººï¼š{host_name}
å˜‰å®¾ï¼š{guests_intro}

## è§’è‰²è®¾å®š
{characters_str}

{knowledge_section}{analysis_section}

## ğŸ™ï¸ æ’­å®¢å¼€åœºç»“æ„è¦æ±‚

**ç¬¬1æ®µ - ä¸»æŒäººå¼€åœºç™½**ï¼š
- {host_name}è‡ªæˆ‘ä»‹ç»ï¼Œæ¬¢è¿å¬ä¼—
- ç®€è¦è¯´æ˜ä»Šå¤©çš„ä¸»é¢˜ï¼š{form.topic}
- è¥é€ {form.atmosphere.value}çš„æ°›å›´

**ç¬¬2æ®µ - ä»‹ç»å˜‰å®¾**ï¼š
- {host_name}ä»‹ç»æ¯ä½å˜‰å®¾çš„èº«ä»½ã€ä¸“ä¸šèƒŒæ™¯
- çªå‡ºå˜‰å®¾åœ¨è¯¥è¯é¢˜ä¸Šçš„ä¸“é•¿

**ç¬¬3-4æ®µ - å¼•å…¥æ ¸å¿ƒè¯é¢˜**ï¼š
- {host_name}æå‡ºæ ¸å¿ƒé—®é¢˜æˆ–è®ºç‚¹
- å˜‰å®¾ç®€è¦å›åº”ï¼Œè¡¨æ˜å„è‡ªè§‚ç‚¹
- ä¸ºåç»­æ·±å…¥è®¨è®ºé“ºå«

## ğŸ­ å¯¹è¯é£æ ¼ï¼ˆæ ¸å¿ƒè¦æ±‚ - å¼ºåˆ¶æ‰§è¡Œï¼‰

**1. ä¸¥æ ¼ä¾æ®è§’è‰²æ·±åº¦äººè®¾ï¼š**
- å¦‚æœè§’è‰²æœ‰"èƒŒæ™¯æ•…äº‹"ï¼Œå¿…é¡»åœ¨å¯¹è¯ä¸­è‡ªç„¶èå…¥ç›¸å…³ç»å†æˆ–æ¡ˆä¾‹
- å¦‚æœè§’è‰²æœ‰"è¯­è¨€ä¹ æƒ¯"æˆ–"å£å¤´ç¦…"ï¼Œå¿…é¡»åœ¨å¯¹è¯ä¸­ä½“ç°
- å¦‚æœè§’è‰²æœ‰"å†…åœ¨çŸ›ç›¾"ï¼Œå¯åœ¨é€‚å½“æ—¶å€™æš—ç¤ºæˆ–æµéœ²

**2. ã€å¼ºåˆ¶ã€‘è§‚ç‚¹å¿…é¡»é…æ¡ˆä¾‹/æ•…äº‹ï¼š**
- âŒ ç¦æ­¢å¹²å·´å·´é™ˆè¿°ï¼š"æ–°èƒ½æºè½¦ç¡®å®æœ‰é—®é¢˜ï¼Œæ¶ˆè´¹è€…å¾ˆæ‹…å¿ƒã€‚"
- âœ… å¿…é¡»æœ‰å…·ä½“æ¡ˆä¾‹ï¼š"å»å¹´æˆ‘ä»¬å¤„ç†è¿‡ä¸€èµ·ç”µæ± çƒ­å¤±æ§çš„å®¢è¯‰ï¼Œè½¦ä¸»åŠå¤œè¢«æ¶ˆé˜²åµé†’ï¼Œæ•´ä¸ªäººéƒ½å“å‚»äº†ã€‚è™½ç„¶æœ€åæŸ¥å‡ºæ¥ä¸æ˜¯è´¨é‡é—®é¢˜ï¼Œä½†è¿™äº‹å„¿å¯¹ä¸€ä¸ªå®¶åº­çš„å†²å‡»å¤ªå¤§äº†ã€‚"

**3. æ¡ˆä¾‹å¿…é¡»å…·ä½“åˆ°ç»†èŠ‚ï¼š**
- å¿…é¡»æœ‰æ•°å­—ï¼ˆå¦‚"20äººè´¨æ£€ç»„â†’2å°è®¾å¤‡"ï¼‰
- å¿…é¡»æœ‰åœºæ™¯ï¼ˆå¦‚"åŠå¤œ"ã€"å·¥å‚è½¦é—´"ã€"è´¨æ£€ç»„"ï¼‰
- å¿…é¡»æœ‰æƒ…æ„Ÿå†²å‡»ï¼ˆå¦‚"æ•´ä¸ªäººéƒ½å“å‚»äº†"ã€"è¿™å¯¹æˆ‘è§¦åŠ¨å¾ˆå¤§"ï¼‰

**4. çœŸå®å¯¹è¯è´¨æ„Ÿï¼š**
- å¤šç”¨"æˆ‘è§‰å¾—"ã€"å…¶å®"ã€"è¯´å®è¯"ã€"ä½ çœ‹"ç­‰å£è¯­è¿æ¥è¯
- å¯ä»¥æœ‰åœé¡¿ã€è½¬æŠ˜ã€è‡ªæˆ‘ä¿®æ­£ï¼ˆå¦‚"ä¸å¯¹ï¼Œåº”è¯¥è¯´..."ï¼‰
- ç”¨æ¯”å–»ã€ç±»æ¯”è®©æŠ½è±¡è§‚ç‚¹å˜å…·ä½“

## âš ï¸ è¾“å‡ºæ ¼å¼ï¼ˆä¸¥æ ¼éµå®ˆï¼‰

{{
  "dialogues": [
    {{
      "character_name": "{host_name}",
      "content": "ä¸»æŒäººå¼€åœºç™½å†…å®¹ï¼ˆçº¯æ–‡æœ¬ï¼‰",
      "emotion": "çƒ­æƒ…"
    }},
    {{
      "character_name": "{host_name}",
      "content": "ä»‹ç»å˜‰å®¾çš„å†…å®¹",
      "emotion": "å‹å¥½"
    }},
    {{
      "character_name": "{host_name}",
      "content": "æå‡ºæ ¸å¿ƒè¯é¢˜",
      "emotion": "å¥½å¥‡"
    }},
    {{
      "character_name": "{guest_names[0] if guest_names else 'å˜‰å®¾'}",
      "content": "å˜‰å®¾å›åº”",
      "emotion": "æ€è€ƒ"
    }}
  ]
}}

æ³¨æ„ï¼š
- ç›´æ¥è¾“å‡ºJSONï¼Œä¸è¦ç”¨```åŒ…è£¹
- contentå¿…é¡»æ˜¯çº¯æ–‡æœ¬ï¼Œä¸å«ç‰¹æ®Šå­—ç¬¦
- ç”Ÿæˆ4-5æ®µå¼€åœºå¯¹è¯

ç°åœ¨ç”Ÿæˆå¼€åœºï¼š"""

    def generate_continue_prompt(self, form: PodcastCustomForm, next_speaker: str,
                                rag_context: Dict[str, Any] = None) -> str:
        """ç”Ÿæˆå¾ªç¯Prompt - å¼•å¯¼å˜‰å®¾æ·±å…¥è®¨è®ºå„è‡ªè§‚ç‚¹ï¼ˆé›†æˆRAGçŸ¥è¯†æ”¯æŒï¼‰"""
        # æ„å»ºå¯¹è¯å†å²ï¼ˆåªä¿ç•™æœ€è¿‘4è½®ï¼‰
        history_text = "\n".join([
            f"{dialogue.character_name}ï¼š{dialogue.content}"
            for dialogue in self.conversation_history[-4:]
        ])

        # æ„å»ºRAGçŸ¥è¯†å‚è€ƒéƒ¨åˆ†
        rag_knowledge_section = ""
        if rag_context and rag_context.get("knowledge_points"):
            # è·å–ç›¸å…³çš„çŸ¥è¯†ç‚¹ï¼ˆæœ€å¤š3ä¸ªï¼‰
            relevant_knowledge = rag_context["knowledge_points"][:3]
            if relevant_knowledge:
                knowledge_items = []
                for idx, point in enumerate(relevant_knowledge, 1):
                    # æ·»åŠ ç½®ä¿¡åº¦æ ‡è®°ï¼ˆåŸºäºsourceç±»å‹ï¼‰
                    confidence = self._calculate_knowledge_confidence(point)
                    confidence_marker = "ğŸŸ¢" if confidence >= 0.8 else "ğŸŸ¡" if confidence >= 0.6 else "ğŸŸ "
                    knowledge_items.append(
                        f"{idx}. {confidence_marker} {point['content'][:200]}..."
                        f"\n   æ¥æº: {point.get('source', 'unknown')}"
                    )

                rag_knowledge_section = f"""
## ğŸ“š çŸ¥è¯†åº“å‚è€ƒï¼ˆå¯é€‰å¼•ç”¨ï¼Œå¢å¼ºè®ºè¿°æ·±åº¦ï¼‰
{chr(10).join(knowledge_items)}

**ä½¿ç”¨æŒ‡å¼•**ï¼š
- å¦‚æœä¸Šè¿°çŸ¥è¯†ä¸å½“å‰è®¨è®ºç›¸å…³ï¼Œå¯è‡ªç„¶èå…¥å¯¹è¯ï¼ˆä¸è¦ç”Ÿç¡¬å¼•ç”¨ï¼‰
- å¯ä»¥æŒ‘æˆ˜æˆ–è´¨ç–‘çŸ¥è¯†åº“å†…å®¹ï¼Œä¿æŒæ‰¹åˆ¤æ€§æ€ç»´
- ç»¿è‰²ğŸŸ¢=é«˜å¯ä¿¡åº¦ï¼Œé»„è‰²ğŸŸ¡=ä¸­ç­‰å¯ä¿¡åº¦ï¼Œæ©™è‰²ğŸŸ =éœ€éªŒè¯
"""

        # è®¡ç®—è¿›åº¦
        progress_ratio = self.current_word_count / self.target_word_count if self.target_word_count > 0 else 0

        # è¯†åˆ«ä¸»æŒäººå’Œå˜‰å®¾
        host_name = self.characters_list[0] if self.characters_list else "ä¸»æŒäºº"
        is_host = (next_speaker == host_name)

        # æ ¹æ®è¿›åº¦ç»™å‡ºå†…å®¹å»ºè®®
        if progress_ratio < 0.3:
            stage_hint = "å±•å¼€è®¨è®º"
            if is_host:
                content_guide = "ä¸»æŒäººå¼•å¯¼å˜‰å®¾æ·±å…¥é˜è¿°å„è‡ªè§‚ç‚¹ï¼Œå¯ä»¥æå‡ºå…·ä½“é—®é¢˜"
            else:
                content_guide = f"{next_speaker}è¯¦ç»†é˜è¿°è‡ªå·±çš„è§‚ç‚¹ï¼Œå¯ä»¥ä¸¾ä¾‹è¯´æ˜"
        elif progress_ratio < 0.7:
            stage_hint = "è§‚ç‚¹ç¢°æ’"
            if is_host:
                content_guide = "ä¸»æŒäººä¿ƒè¿›å˜‰å®¾ä¹‹é—´çš„äº’åŠ¨ï¼Œå¼•å¯¼è§‚ç‚¹äº¤é”‹æˆ–è¡¥å……"
            else:
                content_guide = f"{next_speaker}å›åº”å…¶ä»–äººçš„è§‚ç‚¹ï¼Œå¯ä»¥è¡¨ç¤ºè®¤åŒæˆ–æå‡ºä¸åŒçœ‹æ³•"
        else:
            stage_hint = "å‡†å¤‡æ”¶å°¾"
            if is_host:
                content_guide = "ä¸»æŒäººå¼€å§‹å¼•å¯¼å‘ç»“è®ºï¼Œæ¢³ç†å…³é”®è§‚ç‚¹"
            else:
                content_guide = f"{next_speaker}æ€»ç»“è‡ªå·±çš„æ ¸å¿ƒè§‚ç‚¹"

        # è·å–æœ€è¿‘çš„å‘è¨€å†…å®¹ï¼Œç”¨äºå¼•å¯¼äº’åŠ¨
        last_speaker = ""
        last_content_snippet = ""
        if self.conversation_history:
            last_dialogue = self.conversation_history[-1]
            last_speaker = last_dialogue.character_name
            last_content_snippet = last_dialogue.content[:80] + "..." if len(last_dialogue.content) > 80 else last_dialogue.content

        interaction_guide = ""
        if last_speaker and last_speaker != next_speaker:
            interaction_guide = f"""
## ğŸ¯ã€æ ¸å¿ƒè§„åˆ™1ï¼šå›åº”ä¸åé©³ã€‘å¿…é¡»åŸºäºå‰ä¸€å‘è¨€è¿›è¡Œäº’åŠ¨
ä¸Šä¸€ä½å‘è¨€è€…ï¼ˆ{last_speaker}ï¼‰è¯´äº†ï¼š"{last_content_snippet}"

**{next_speaker}çš„å‘è¨€å¿…é¡»éµå¾ª"ä¹’ä¹“çƒè§„åˆ™"ï¼š**

1. **å¼€å¤´å¿…é¡»ç›´æ¥å›åº”**ï¼ˆé€‰æ‹©å…¶ä¸€ï¼‰ï¼š
   - è®¤åŒå¹¶è¡¥å……ï¼š"å¯¹ï¼Œ{last_speaker}è¯´çš„è¿™ä¸ªæˆ‘æ·±æœ‰æ„Ÿè§¦/å®Œå…¨åŒæ„ã€‚æˆ‘è¿˜æƒ³è¡¥å……çš„æ˜¯..."
   - éƒ¨åˆ†è®¤åŒå¹¶è½¬æŠ˜ï¼š"æ‚¨è¯´çš„XXè¿™ç‚¹æˆ‘è®¤åŒï¼Œä½†å…³äºXXï¼Œæˆ‘æœ‰ä¸åŒçœ‹æ³•..."
   - è´¨ç–‘å¹¶åé©³ï¼š"æ‚¨æåˆ°çš„XXï¼Œæˆ‘æœ‰ä¸ªç–‘é—®/æˆ‘è§‰å¾—å¯èƒ½ä¸å®Œå…¨æ˜¯è¿™æ ·ã€‚æ‚¨çœ‹..."
   - è¿½é—®æ·±æŒ–ï¼š"æ‚¨åˆšæ‰è¯´çš„XXç‰¹åˆ«æœ‰æ„æ€ï¼Œèƒ½ä¸èƒ½å±•å¼€è¯´è¯´ï¼Ÿæ¯”å¦‚..."

2. **ä¸¥ç¦è‡ªè¯´è‡ªè¯**ï¼š
   - âŒ ç¦æ­¢ï¼š"æˆ‘è®¤ä¸ºXXæ˜¯ä¸ªé—®é¢˜ã€‚"ï¼ˆå®Œå…¨æ— è§†{last_speaker}çš„å‘è¨€ï¼‰
   - âœ… å¿…é¡»ï¼š"æ‚¨åˆšæ‰æåˆ°XXï¼Œè¿™è®©æˆ‘æƒ³åˆ°æˆ‘ä»¬å…¬å¸å»å¹´çš„ä¸€ä¸ªæ¡ˆä¾‹..."

3. **åˆ¶é€ æ€æƒ³ç¢°æ’**ï¼š
   - å¦‚æœ{last_speaker}æä¾›äº†æ¡ˆä¾‹ï¼Œ{next_speaker}å¿…é¡»è¿½é—®ç»†èŠ‚æˆ–æå‡ºè´¨ç–‘
   - å¦‚æœ{last_speaker}æå‡ºäº†è§‚ç‚¹ï¼Œ{next_speaker}å¿…é¡»è¡¨æ€ï¼ˆæ”¯æŒ/åå¯¹/è¡¥å……ï¼‰
"""

        return f"""ç»§ç»­æ’­å®¢å¯¹è¯ã€‚å½“å‰è¿›åº¦ï¼š{self.current_word_count}/{self.target_word_count}å­—

## å·²æœ‰å¯¹è¯ï¼ˆæœ€è¿‘4è½®ï¼‰
{history_text}
{rag_knowledge_section}
{interaction_guide}
## ä¸‹ä¸€æ­¥ç”Ÿæˆ
- å½“å‰é˜¶æ®µï¼š{stage_hint}
- ä¸‹ä¸€ä½å‘è¨€è€…ï¼šã€{next_speaker}ã€‘
- å†…å®¹æ–¹å‘ï¼š{content_guide}
- ç”Ÿæˆ2-3æ®µå¯¹è¯

## ğŸ­ å¯¹è¯è¦æ±‚ï¼ˆæ ¸å¿ƒå‡†åˆ™ - ä¸‰å¤§é“å¾‹ï¼‰

**ã€é“å¾‹1ï¼šè§‚ç‚¹å¿…é¡»é…æ¡ˆä¾‹ã€‘**
- âŒ ç»å¯¹ç¦æ­¢ï¼š"æˆ‘è®¤ä¸ºæˆæœ¬æ˜¯ä¸ªé—®é¢˜ã€‚"ï¼ˆçº¯è§‚ç‚¹é™ˆè¿°ï¼‰
- âœ… å¼ºåˆ¶è¦æ±‚ï¼šè§‚ç‚¹ + å…·ä½“æ¡ˆä¾‹ï¼ˆå«æ•°å­—ã€åœºæ™¯ã€æƒ…æ„Ÿï¼‰
- ç¤ºä¾‹ï¼š"è¯´åˆ°æˆæœ¬ï¼Œå»å¹´æˆ‘æœ‹å‹ä¹°ç”µåŠ¨è½¦èŠ±äº†20ä¸‡ï¼Œç°åœ¨ç”µæ± è¡°å‡åˆ°60%ï¼Œä»–è¯´æ„Ÿè§‰åƒä¹°äº†ä¸ª'åˆ°æœŸé£Ÿå“'ï¼Œä¸‰å¹´è´¬å€¼ä¸€åŠã€‚è¿™è°å—å¾—äº†ï¼Ÿ"

**ã€é“å¾‹2ï¼šå¿…é¡»å›åº”å‰ä¸€å‘è¨€ã€‘**
- âŒ ä¸¥ç¦å„è¯´å„è¯ï¼š"æˆ‘è®¤ä¸ºAIä¼šåˆ›é€ æ–°å²—ä½ã€‚"ï¼ˆæ— è§†å¯¹æ–¹ï¼‰
- âœ… å¼ºåˆ¶å¼€å¤´å›åº”ï¼š"æ‚¨åˆšæ‰è¯´çš„é‚£ä¸ªè´¨æ£€ç»„æ¡ˆä¾‹ï¼Œæˆ‘ç‰¹åˆ«æœ‰å…±é¸£ã€‚æˆ‘ä»¬å…¬å¸å»å¹´..."
- å¿…é¡»ä½¿ç”¨çš„äº’åŠ¨å¥å¼ï¼š
  * è¿½é—®ï¼š"æ‚¨æåˆ°XXï¼Œèƒ½è¯¦ç»†è¯´è¯´é‚£19ä¸ªå‘˜å·¥åæ¥æ€ä¹ˆæ ·äº†å—ï¼Ÿ"
  * è´¨ç–‘ï¼š"ä½†æˆ‘æœ‰ä¸ªç–‘é—®ï¼Œæ‚¨è¯´çš„æ–°å²—ä½ï¼ŒçœŸèƒ½å¼¥è¡¥å¤±å»çš„é‚£ä¹ˆå¤šä¼ ç»Ÿå²—ä½å—ï¼Ÿ"
  * è¡¥å……ï¼š"å¯¹ï¼Œæˆ‘å®Œå…¨åŒæ„ã€‚è€Œä¸”æˆ‘è¿˜æƒ³è¡¥å……çš„æ˜¯..."

**ã€é“å¾‹3ï¼šè¿½é—®æ·±æŒ–ï¼Œåˆ¶é€ æ€æƒ³ç«èŠ±ã€‘**
- å½“å¯¹æ–¹åˆ†äº«æ¡ˆä¾‹æ—¶ï¼Œå¿…é¡»è¿½é—®èƒŒåçš„ç»†èŠ‚æˆ–å¼•ç”³é—®é¢˜
- ç¤ºä¾‹å¯¹è¯æµï¼š
  * Aï¼š"æˆ‘ä»¬å·¥å‚20äººè´¨æ£€ç»„è¢«2å°è®¾å¤‡æ›¿ä»£äº†ã€‚"
  * Bï¼šã€å¿…é¡»è¿½é—®ã€‘"é‚£19ä¸ªäººåæ¥æ€ä¹ˆåŠçš„ï¼Ÿè½¬å²—æˆåŠŸç‡é«˜å—ï¼Ÿ"
  * Aï¼šã€å¿…é¡»å›åº”ã€‘"è¯´å®è¯ï¼Œåªæœ‰3-4ä¸ªæˆåŠŸè½¬å²—ï¼Œå‰©ä¸‹çš„..."
  * Bï¼šã€å¿…é¡»æ·±æŒ–ã€‘"è¿™å°±æ˜¯æˆ‘æ‹…å¿ƒçš„ï¼3-4ä¸ªæˆåŠŸç‡å¤ªä½äº†ï¼Œè¿™è¯´æ˜..."

**ã€é“å¾‹4ï¼šçœŸå®å£è¯­åŒ–ã€‘**
- ç”¨"ä½ çœ‹"ã€"å…¶å®"ã€"è¯´ç™½äº†"ã€"è¯´å®è¯"å¼€å¤´
- æœ‰åœé¡¿æ„Ÿï¼š"è¿™ä¸ªäº‹æƒ…â€¦â€¦æ€ä¹ˆè¯´å‘¢â€¦â€¦""ä¸å¯¹ï¼Œåº”è¯¥è¿™ä¹ˆè¯´..."

## âš ï¸ è¾“å‡ºæ ¼å¼

{{
  "dialogues": [
    {{
      "character_name": "{next_speaker}",
      "content": "å¯¹è¯å†…å®¹",
      "emotion": "æ€è€ƒ"
    }}
  ]
}}

æ³¨æ„ï¼šç›´æ¥è¾“å‡ºJSONï¼Œä¸è¦ç”¨```åŒ…è£¹

ç°åœ¨ç”Ÿæˆï¼š"""

    async def generate_script(self, form: PodcastCustomForm) -> PodcastScript:
        """ä½¿ç”¨çŠ¶æ€åŒ–å¾ªç¯ç”Ÿæˆæœºåˆ¶ç”Ÿæˆæ’­å®¢å‰§æœ¬ï¼ˆé›†æˆRAGçŸ¥è¯†æ£€ç´¢ï¼‰"""
        print(f"[DEBUG] å¼€å§‹ç”Ÿæˆè„šæœ¬ï¼Œä¸»é¢˜: {form.topic}")
        print(f"[DEBUG] è§’è‰²æ•°é‡: {len(form.characters)}")
        print(f"[DEBUG] ä½¿ç”¨çš„å®¢æˆ·ç«¯ç±»å‹: {type(self.deepseek_client).__name__}")

        # åˆå§‹åŒ–ç”ŸæˆçŠ¶æ€
        self.initialize_generation_state(form)
        print(f"[DEBUG] ç”ŸæˆçŠ¶æ€åˆå§‹åŒ–å®Œæˆï¼Œç›®æ ‡å­—æ•°: {self.target_word_count}")

        # ç¬¬ä¸€æ­¥+ç¬¬äºŒæ­¥ï¼šå¹¶è¡Œæ‰§è¡ŒRAGçŸ¥è¯†æ£€ç´¢å’ŒGeminiç´ æåˆ†æï¼ˆæ€§èƒ½ä¼˜åŒ–ï¼‰
        rag_context = None
        analysis_result = None

        # å‡†å¤‡å¹¶è¡Œä»»åŠ¡
        parallel_tasks = []

        # ä»»åŠ¡1ï¼šRAGçŸ¥è¯†æ£€ç´¢
        async def rag_task():
            """RAGçŸ¥è¯†æ£€ç´¢ä»»åŠ¡"""
            if not getattr(settings, 'rag_enabled', False):
                print("[RAG] RAGåŠŸèƒ½å·²ç¦ç”¨")
                return None

            try:
                await self.rag_service.ensure_ready()
                print(f"[RAG] æ­£åœ¨æ£€ç´¢ç›¸å…³çŸ¥è¯†: {form.topic}")
                character_names = [char.name for char in form.characters]
                context = await self.rag_service.get_podcast_context(form.topic, character_names)

                if context and context.get("knowledge_points"):
                    print(f"[RAG] æˆåŠŸè·å– {len(context['knowledge_points'])} ä¸ªçŸ¥è¯†ç‚¹")
                else:
                    print(f"[RAG] æœªæ‰¾åˆ°ç›¸å…³çŸ¥è¯†")
                return context
            except Exception as e:
                print(f"[RAG] çŸ¥è¯†æ£€ç´¢å¤±è´¥: {str(e)}")
                return None

        # ä»»åŠ¡2ï¼šGeminiç´ æåˆ†æ
        async def analysis_task():
            """Geminiç´ æåˆ†æä»»åŠ¡"""
            if not form.background_materials:
                print("[åˆ†æ] æ— èƒŒæ™¯ç´ æï¼Œè·³è¿‡åˆ†æ")
                return None

            try:
                print(f"[åˆ†æ] å¼€å§‹åˆ†æèƒŒæ™¯ç´ æ...")
                result = await self.analyze_materials(form.background_materials)
                print(f"[åˆ†æ] ç´ æåˆ†æå®Œæˆ")
                return result
            except Exception as e:
                print(f"[åˆ†æ] ç´ æåˆ†æå¤±è´¥: {str(e)}")
                return None

        # åˆ¤æ–­éœ€è¦æ‰§è¡Œå“ªäº›ä»»åŠ¡
        tasks_to_run = []
        task_names = []

        if getattr(settings, 'rag_enabled', False):
            tasks_to_run.append(rag_task())
            task_names.append("RAGæ£€ç´¢")

        if form.background_materials:
            tasks_to_run.append(analysis_task())
            task_names.append("ç´ æåˆ†æ")

        # å¹¶è¡Œæ‰§è¡Œæ‰€æœ‰ä»»åŠ¡ï¼ˆå¦‚æœæœ‰å¤šä¸ªä»»åŠ¡ï¼‰
        if len(tasks_to_run) > 1:
            print(f"[å¹¶è¡Œ] å¼€å§‹å¹¶è¡Œæ‰§è¡Œ: {', '.join(task_names)}")
            import asyncio
            results = await asyncio.gather(*tasks_to_run, return_exceptions=True)

            # åˆ†é…ç»“æœ
            result_index = 0
            if getattr(settings, 'rag_enabled', False):
                rag_context = results[result_index] if not isinstance(results[result_index], Exception) else None
                result_index += 1

            if form.background_materials:
                analysis_result = results[result_index] if not isinstance(results[result_index], Exception) else None

            print(f"[å¹¶è¡Œ] å¹¶è¡Œä»»åŠ¡å®Œæˆ")
        elif len(tasks_to_run) == 1:
            # åªæœ‰ä¸€ä¸ªä»»åŠ¡ï¼Œç›´æ¥æ‰§è¡Œ
            result = await tasks_to_run[0]
            if getattr(settings, 'rag_enabled', False):
                rag_context = result
            elif form.background_materials:
                analysis_result = result
        else:
            print("[INFO] æ— éœ€æ‰§è¡ŒRAGæ£€ç´¢æˆ–ç´ æåˆ†æ")

        # ç¬¬ä¸‰æ­¥ï¼šç”Ÿæˆå¼€åœºç™½å’Œç¬¬ä¸€è½®å¯¹è¯
        try:
            print(f"[DEBUG] å¼€å§‹ç”Ÿæˆåˆå§‹å¯¹è¯...")
            initial_prompt = self.generate_initial_prompt(form, analysis_result, rag_context)
            print(f"[DEBUG] åˆå§‹Promptç”Ÿæˆå®Œæˆï¼Œé•¿åº¦: {len(initial_prompt)}")

            print(f"[DEBUG] è°ƒç”¨å®¢æˆ·ç«¯ç”Ÿæˆåˆå§‹å¯¹è¯...")
            response = await self.deepseek_client.chat.completions.create(
                model=settings.deepseek_model,
                messages=[{"role": "user", "content": initial_prompt}],
                temperature=0.7  # é™ä½temperatureï¼Œå‡å°‘éšæœºæ€§å’Œé‡å¤
            )

            print(f"[DEBUG] å®¢æˆ·ç«¯å“åº”æ”¶åˆ°ï¼Œç±»å‹: {type(response)}")
            result_text = response.choices[0].message.content
            print(f"[DEBUG] å“åº”å†…å®¹é•¿åº¦: {len(result_text)}, å‰100å­—ç¬¦: {result_text[:100]}")

            # æ¸…ç†JSONå­—ç¬¦ä¸²ï¼ˆç§»é™¤æ§åˆ¶å­—ç¬¦å’Œä¿®å¤æ ¼å¼ï¼‰
            result_text = result_text.strip()

            # æå–JSONéƒ¨åˆ†ï¼ˆå¦‚æœLLMè¾“å‡ºäº†é¢å¤–çš„æ–‡æœ¬ï¼‰
            if "```json" in result_text:
                # ç§»é™¤markdownä»£ç å—æ ‡è®°
                result_text = result_text.split("```json")[1].split("```")[0].strip()
            elif "```" in result_text:
                result_text = result_text.split("```")[1].split("```")[0].strip()

            # æ›¿æ¢æ§åˆ¶å­—ç¬¦ä¸ºè½¬ä¹‰åºåˆ—
            import re
            # æ›¿æ¢æœªè½¬ä¹‰çš„æ¢è¡Œç¬¦ã€åˆ¶è¡¨ç¬¦ç­‰
            result_text = result_text.replace('\n', '\\n').replace('\r', '\\r').replace('\t', '\\t')
            # ä½†è¦ä¿ç•™JSONç»“æ„ä¸­çš„æ¢è¡Œ
            result_text = re.sub(r'\\n\s*\\n', '\\n', result_text)  # åˆå¹¶å¤šä½™æ¢è¡Œ

            print(f"[DEBUG] æ¸…ç†åçš„JSONå‰200å­—ç¬¦: {result_text[:200]}")

            try:
                initial_data = json.loads(result_text)
            except json.JSONDecodeError as je:
                print(f"[DEBUG] JSONè§£æå¤±è´¥ï¼Œå°è¯•ä¿®å¤...")
                # å°è¯•ç§»é™¤æ‰€æœ‰æ¢è¡Œå’Œå¤šä½™ç©ºæ ¼
                result_text_clean = re.sub(r'\\[nrt]', ' ', result_text)
                result_text_clean = re.sub(r'\s+', ' ', result_text_clean)
                print(f"[DEBUG] å†æ¬¡å°è¯•è§£æï¼Œæ¸…ç†å: {result_text_clean[:200]}")
                try:
                    initial_data = json.loads(result_text_clean)
                except:
                    print(f"[DEBUG] å®Œæ•´å“åº”å†…å®¹:\n{result_text}")
                    raise je  # é‡æ–°æŠ›å‡ºåŸå§‹é”™è¯¯

            print(f"[DEBUG] JSONè§£ææˆåŠŸï¼Œå¯¹è¯æ•°é‡: {len(initial_data.get('dialogues', []))}")

            # æ·»åŠ åˆå§‹å¯¹è¯åˆ°å†å²
            for dialogue_data in initial_data["dialogues"]:
                # ã€é‡è¦ã€‘æ¸…ç†LLMç”Ÿæˆçš„æ–‡æœ¬ï¼Œç§»é™¤å¯èƒ½æ··å…¥çš„æƒ…ç»ªæ ‡æ³¨
                original_content = dialogue_data["content"]
                cleaned_content = clean_for_tts(original_content, emotion=dialogue_data.get("emotion"))

                # è®°å½•æ¸…ç†æƒ…å†µï¼ˆä¾¿äºè°ƒè¯•ï¼‰
                if cleaned_content != original_content:
                    print(f"[CLEAN] å‰§æœ¬ç”Ÿæˆé˜¶æ®µæ¸…ç†: [{original_content[:50]}...] -> [{cleaned_content[:50]}...]")

                dialogue = ScriptDialogue(
                    character_name=dialogue_data["character_name"],
                    content=cleaned_content,  # ä½¿ç”¨æ¸…ç†åçš„å†…å®¹
                    emotion=dialogue_data.get("emotion")
                )
                self.conversation_history.append(dialogue)

            # æ›´æ–°å­—æ•°ç»Ÿè®¡
            self.current_word_count = self.count_words_in_history()
            print(f"[DEBUG] åˆå§‹å¯¹è¯æ·»åŠ å®Œæˆï¼Œå½“å‰å­—æ•°: {self.current_word_count}")

        except Exception as e:
            print(f"[DEBUG] åˆå§‹å¯¹è¯ç”Ÿæˆå¤±è´¥: {str(e)}")
            print(f"[DEBUG] å¼‚å¸¸ç±»å‹: {type(e).__name__}")
            import traceback
            print(f"[DEBUG] å¼‚å¸¸è¯¦ç»†: {traceback.format_exc()}")
            raise Exception(f"åˆå§‹å¯¹è¯ç”Ÿæˆå¤±è´¥: {str(e)}")

        print(f"[DEBUG] å¼€å§‹å¾ªç¯ç”Ÿæˆå¯¹è¯...")
        # ç¬¬å››æ­¥ï¼šå¾ªç¯ç”Ÿæˆå¯¹è¯ç›´åˆ°æ»¡è¶³ç»ˆæ­¢æ¡ä»¶
        max_iterations = 15  # é˜²æ­¢æ— é™å¾ªç¯
        iteration = 0

        while not self.should_terminate() and iteration < max_iterations:
            try:
                print(f"[DEBUG] å¾ªç¯ç¬¬ {iteration + 1} è½®...")
                # å†³å®šä¸‹ä¸€ä½å‘è¨€è€…
                next_speaker = self.get_next_speaker()
                print(f"[DEBUG] ä¸‹ä¸€ä½å‘è¨€è€…: {next_speaker}")

                # ç”Ÿæˆç»§ç»­å¯¹è¯çš„promptï¼ˆå¯èƒ½åŒ…å«RAGçŸ¥è¯†ï¼‰
                continue_prompt = self.generate_continue_prompt(form, next_speaker, rag_context)

                # è°ƒç”¨LLMç”Ÿæˆä¸‹ä¸€è½®å¯¹è¯
                response = await self.deepseek_client.chat.completions.create(
                    model=settings.deepseek_model,
                    messages=[{"role": "user", "content": continue_prompt}],
                    temperature=0.7  # é™ä½temperatureï¼Œå‡å°‘éšæœºæ€§
                )

                result_text = response.choices[0].message.content.strip()

                # æ¸…ç†JSONï¼ˆåŒåˆå§‹å¯¹è¯ï¼‰
                if "```json" in result_text:
                    result_text = result_text.split("```json")[1].split("```")[0].strip()
                elif "```" in result_text:
                    result_text = result_text.split("```")[1].split("```")[0].strip()

                result_text = result_text.replace('\n', '\\n').replace('\r', '\\r').replace('\t', '\\t')
                result_text = re.sub(r'\\n\s*\\n', '\\n', result_text)

                try:
                    continue_data = json.loads(result_text)
                except json.JSONDecodeError:
                    result_text_clean = re.sub(r'\\[nrt]', ' ', result_text)
                    result_text_clean = re.sub(r'\s+', ' ', result_text_clean)
                    continue_data = json.loads(result_text_clean)

                # æ·»åŠ æ–°å¯¹è¯åˆ°å†å²ï¼ˆå¸¦å»é‡æ£€æŸ¥ã€äº‹å®æ ¡éªŒå’Œå®‰å…¨å®ˆæŠ¤ï¼‰
                for dialogue_data in continue_data["dialogues"]:
                    # ã€é‡è¦ã€‘æ¸…ç†LLMç”Ÿæˆçš„æ–‡æœ¬ï¼Œç§»é™¤å¯èƒ½æ··å…¥çš„æƒ…ç»ªæ ‡æ³¨
                    original_content = dialogue_data["content"]
                    cleaned_content = clean_for_tts(original_content, emotion=dialogue_data.get("emotion"))

                    # ã€æ–°å¢ã€‘æ£€æŸ¥å†…å®¹é‡å¤
                    if self.check_content_repetition(cleaned_content):
                        print(f"[WARN] æ£€æµ‹åˆ°é‡å¤å†…å®¹ï¼Œè·³è¿‡: {cleaned_content[:50]}...")
                        continue

                    # ã€æ–°å¢ã€‘å†…å®¹å®‰å…¨å®ˆæŠ¤
                    is_safe, safety_message = self.validate_content_safety(cleaned_content, rag_context)
                    if not is_safe:
                        print(f"[SAFETY] âš ï¸ å†…å®¹å®‰å…¨éªŒè¯å¤±è´¥")
                        print(f"[SAFETY]   - é—®é¢˜: {safety_message}")
                        # å½“å‰ç­–ç•¥ï¼šè®°å½•è­¦å‘Šä½†ä»ç„¶ä¿ç•™å†…å®¹ï¼ˆç”Ÿäº§ç¯å¢ƒå»ºè®®è·³è¿‡ï¼‰
                        # continue  # å–æ¶ˆæ³¨é‡Šæ­¤è¡Œä»¥åœ¨æ£€æµ‹åˆ°å®‰å…¨é—®é¢˜æ—¶è·³è¿‡å†…å®¹

                    # ã€æ–°å¢ã€‘RAGäº‹å®æ ¡éªŒå±‚
                    if rag_context and rag_context.get("knowledge_points"):
                        validation_result = self._validate_against_knowledge(cleaned_content, rag_context)
                        if not validation_result["is_valid"]:
                            print(f"[FACT-CHECK] âš ï¸ å†…å®¹æœªé€šè¿‡äº‹å®æ ¡éªŒ")
                            print(f"[FACT-CHECK]   - ç½®ä¿¡åº¦: {validation_result['confidence']}")
                            print(f"[FACT-CHECK]   - è­¦å‘Š: {validation_result['warnings']}")
                            print(f"[FACT-CHECK]   - å†²çª: {validation_result['conflicting_facts']}")
                            # å½“å‰ç­–ç•¥ï¼šè®°å½•è­¦å‘Šä½†ä»ç„¶ä¿ç•™å†…å®¹ï¼ˆå¯æ ¹æ®éœ€è¦è°ƒæ•´ä¸ºè·³è¿‡ï¼‰
                        elif validation_result["warnings"]:
                            print(f"[FACT-CHECK] â„¹ï¸ æ£€æµ‹åˆ° {len(validation_result['warnings'])} ä¸ªæç¤º")
                            for warning in validation_result['warnings'][:2]:  # åªæ˜¾ç¤ºå‰2ä¸ª
                                print(f"[FACT-CHECK]   - {warning}")

                    # è®°å½•æ¸…ç†æƒ…å†µï¼ˆä¾¿äºè°ƒè¯•ï¼‰
                    if cleaned_content != original_content:
                        print(f"[CLEAN] å¾ªç¯å¯¹è¯æ¸…ç†: [{original_content[:50]}...] -> [{cleaned_content[:50]}...]")

                    dialogue = ScriptDialogue(
                        character_name=dialogue_data["character_name"],
                        content=cleaned_content,  # ä½¿ç”¨æ¸…ç†åçš„å†…å®¹
                        emotion=dialogue_data.get("emotion")
                    )
                    self.conversation_history.append(dialogue)

                # æ›´æ–°å­—æ•°ç»Ÿè®¡
                self.current_word_count = self.count_words_in_history()
                print(f"[DEBUG] ç¬¬{iteration + 1}è½®å®Œæˆï¼Œå½“å‰å­—æ•°: {self.current_word_count}")

                iteration += 1

            except Exception as e:
                print(f"å¾ªç¯ç”Ÿæˆç¬¬{iteration+1}è½®å¤±è´¥: {str(e)}")
                break

        print(f"[DEBUG] å¯¹è¯å¾ªç¯å®Œæˆï¼Œæ€»è®¡ {iteration} è½®")

        # ç¬¬äº”æ­¥ï¼šå¦‚æœæ²¡æœ‰è‡ªç„¶ç»“æŸï¼Œç”Ÿæˆç»“æŸè¯­
        if self.conversation_history and not any(
            keyword in self.conversation_history[-1].content
            for keyword in ["æ„Ÿè°¢å¤§å®¶æ”¶å¬", "ä»Šå¤©çš„æ’­å®¢", "æˆ‘ä»¬ä¸‹æœŸå†è§", "è°¢è°¢æ”¶å¬"]
        ):
            print(f"[DEBUG] ç”Ÿæˆç»“æŸè¯­...")
            await self._generate_ending(form)

        # ç¬¬å…­æ­¥ï¼šæ„å»ºæœ€ç»ˆå‰§æœ¬ï¼ˆåŒ…å«RAGæ¥æºä¿¡æ¯ï¼‰
        script = PodcastScript(
            title=form.title or form.topic,
            topic=form.topic,
            dialogues=self.conversation_history
        )

        # å¦‚æœä½¿ç”¨äº†RAGçŸ¥è¯†ï¼Œæ·»åŠ åˆ°å…ƒæ•°æ®
        if rag_context and rag_context.get("knowledge_points"):
            script.metadata = {
                "rag_enabled": True,
                "knowledge_sources": len(rag_context.get("source_summary", {})),
                "knowledge_points_used": len(rag_context["knowledge_points"]),
                "source_summary": rag_context.get("source_summary", {})
            }

        print(f"[DEBUG] è„šæœ¬ç”Ÿæˆå®Œæˆï¼Œæ€»å¯¹è¯æ•°: {len(script.dialogues)}")
        return script

    async def _generate_ending(self, form: PodcastCustomForm):
        """ç”Ÿæˆæ’­å®¢ç»“æŸè¯­ - ä¼˜åŒ–ä¸ºä¸»æŒäººæ€»ç»“+é›†ä½“é“åˆ«"""
        # æ‰¾åˆ°ä¸»æŒäººè§’è‰²ï¼ˆç¬¬ä¸€ä¸ªè§’è‰²ï¼‰
        host_name = self.characters_list[0] if self.characters_list else "ä¸»æŒäºº"

        # æ„å»ºæ‰€æœ‰è§’è‰²åˆ—è¡¨ç”¨äºé›†ä½“é“åˆ«
        all_characters = self.characters_list if self.characters_list else ["ä¸»æŒäºº"]

        ending_prompt = f"""# ä»»åŠ¡ï¼šä¸ºæ’­å®¢ç”Ÿæˆä¸“ä¸šçš„ç»“æŸéƒ¨åˆ†

è¿™æ˜¯ä¸€åœºå…³äº"{form.topic}"çš„æ’­å®¢å³å°†ç»“æŸã€‚

## ç»“æŸæµç¨‹è¦æ±‚

**ç¬¬1æ®µ - ä¸»æŒäººæ€»ç»“**ï¼š
- {host_name}æ€»ç»“ä»Šå¤©è®¨è®ºçš„æ ¸å¿ƒè§‚ç‚¹
- æç‚¼2-3ä¸ªå…³é”®è¦ç‚¹
- å­—æ•°æ§åˆ¶åœ¨60-80å­—

**ç¬¬2æ®µ - ä¸»æŒäººè‡´è°¢**ï¼š
- {host_name}æ„Ÿè°¢å„ä½å˜‰å®¾çš„ç²¾å½©åˆ†äº«
- æ„Ÿè°¢å¬ä¼—çš„æ”¶å¬

**ç¬¬3æ®µ - é›†ä½“é“åˆ«**ï¼š
- {host_name}å¼•å¯¼å¤§å®¶ä¸€èµ·å’Œå¬ä¼—é“åˆ«
- æ‰€æœ‰äººï¼ˆ{', '.join(all_characters)}ï¼‰ä¸€èµ·è¯´"å†è§"æˆ–"æ‹œæ‹œ"
- è¥é€ æ¸©é¦¨çš„ç»“æŸæ°›å›´

## ğŸ­ å¯¹è¯è´¨æ„Ÿè¦æ±‚

**1. çœŸè¯šè€Œéå¥—è·¯ï¼š**
- âŒ ç¦æ­¢ï¼š"ä»Šå¤©çš„è®¨è®ºéå¸¸ç²¾å½©"ï¼ˆç©ºæ´å®¢å¥—ï¼‰
- âœ… å¿…é¡»ï¼š"ä»Šå¤©èŠä¸‹æ¥ï¼Œæˆ‘è‡ªå·±ä¹Ÿæœ‰ä¸å°‘æ”¶è·ã€‚å°¤å…¶æ˜¯ç‹ç»ç†æåˆ°çš„é‚£ä¸ªç”µæ± æ¡ˆä¾‹ï¼ŒçœŸçš„è®©äººæ·±æ€ã€‚"ï¼ˆçœŸè¯šå…·ä½“ï¼‰

**2. è‡ªç„¶å£è¯­åŒ–ï¼š**
- ç”¨"å…¶å®"ã€"è¯´å®è¯"ã€"ä»Šå¤©çœŸçš„"ç­‰å£è¯­è¿æ¥è¯
- å¯ä»¥æœ‰åœé¡¿æ„Ÿï¼š"è¿™ä¸ªé—®é¢˜â€¦â€¦å—¯â€¦â€¦ç¡®å®å€¼å¾—æˆ‘ä»¬ç»§ç»­å…³æ³¨"

## âš ï¸ è¾“å‡ºæ ¼å¼ï¼ˆä¸¥æ ¼éµå®ˆï¼‰

{{
  "dialogues": [
    {{
      "character_name": "{host_name}",
      "content": "æ€»ç»“æ ¸å¿ƒè§‚ç‚¹çš„å†…å®¹",
      "emotion": "è®¤çœŸ"
    }},
    {{
      "character_name": "{host_name}",
      "content": "æ„Ÿè°¢å˜‰å®¾å’Œå¬ä¼—",
      "emotion": "æ¸©æš–"
    }},
    {{
      "character_name": "{host_name}",
      "content": "å¥½çš„ï¼Œè®©æˆ‘ä»¬ä¸€èµ·å’Œå¬ä¼—æœ‹å‹ä»¬è¯´å†è§å§ï¼",
      "emotion": "å¼€å¿ƒ"
    }}
  ]
}}

æ³¨æ„ï¼š
- ç›´æ¥è¾“å‡ºJSONï¼Œä¸è¦ç”¨```åŒ…è£¹
- contentå¿…é¡»æ˜¯çº¯æ–‡æœ¬
- ç”Ÿæˆ3æ®µç»“æŸå¯¹è¯
- æœ€åä¸€æ®µè¦è‡ªç„¶å¼•å¯¼é›†ä½“é“åˆ«

ç°åœ¨ç”Ÿæˆç»“æŸè¯­ï¼š"""

        try:
            response = await self.deepseek_client.chat.completions.create(
                model=settings.deepseek_model,
                messages=[{"role": "user", "content": ending_prompt}],
                temperature=0.6  # ç»“æŸè¯­æ›´ç¨³å®š
            )

            result_text = response.choices[0].message.content.strip()

            # æ¸…ç†JSONï¼ˆåŒåˆå§‹å¯¹è¯ï¼‰
            if "```json" in result_text:
                result_text = result_text.split("```json")[1].split("```")[0].strip()
            elif "```" in result_text:
                result_text = result_text.split("```")[1].split("```")[0].strip()

            result_text = result_text.replace('\n', '\\n').replace('\r', '\\r').replace('\t', '\\t')
            result_text = re.sub(r'\\n\s*\\n', '\\n', result_text)

            try:
                ending_data = json.loads(result_text)
            except json.JSONDecodeError:
                result_text_clean = re.sub(r'\\[nrt]', ' ', result_text)
                result_text_clean = re.sub(r'\s+', ' ', result_text_clean)
                ending_data = json.loads(result_text_clean)

            # æ·»åŠ ç»“æŸè¯­
            for dialogue_data in ending_data["dialogues"]:
                # ã€é‡è¦ã€‘æ¸…ç†LLMç”Ÿæˆçš„æ–‡æœ¬
                original_content = dialogue_data["content"]
                cleaned_content = clean_for_tts(original_content, emotion=dialogue_data.get("emotion"))

                if cleaned_content != original_content:
                    print(f"[CLEAN] ç»“æŸè¯­æ¸…ç†: [{original_content[:50]}...] -> [{cleaned_content[:50]}...]")

                dialogue = ScriptDialogue(
                    character_name=dialogue_data["character_name"],
                    content=cleaned_content,  # ä½¿ç”¨æ¸…ç†åçš„å†…å®¹
                    emotion=dialogue_data.get("emotion")
                )
                self.conversation_history.append(dialogue)

            # ç”Ÿæˆé›†ä½“é“åˆ«
            print(f"[DEBUG] ç”Ÿæˆé›†ä½“é“åˆ«...")
            await self._generate_group_farewell()

        except Exception as e:
            print(f"ç”Ÿæˆç»“æŸè¯­å¤±è´¥: {str(e)}")
            # æ·»åŠ é»˜è®¤ç»“æŸè¯­
            default_ending = ScriptDialogue(
                character_name=host_name,
                content="æ„Ÿè°¢å¤§å®¶æ”¶å¬ä»Šå¤©çš„æ’­å®¢ï¼Œæˆ‘ä»¬ä¸‹æœŸå†è§ï¼",
                emotion="æ¸©æš–"
            )
            self.conversation_history.append(default_ending)

    async def _generate_group_farewell(self):
        """ç”Ÿæˆé›†ä½“é“åˆ«ç¯èŠ‚"""
        # æ‰€æœ‰è§’è‰²ä¸€èµ·è¯´å†è§
        all_characters = self.characters_list if self.characters_list else ["ä¸»æŒäºº"]

        farewell_prompt = f"""# ä»»åŠ¡ï¼šç”Ÿæˆé›†ä½“é“åˆ«ç¯èŠ‚

æ’­å®¢å³å°†ç»“æŸï¼Œæ‰€æœ‰äººè¦ä¸€èµ·å’Œå¬ä¼—é“åˆ«ã€‚

## è§’è‰²åˆ—è¡¨
{', '.join(all_characters)}

## è¦æ±‚
- æ¯ä¸ªè§’è‰²éƒ½è¦è¯´ä¸€å¥ç®€çŸ­çš„é“åˆ«è¯­
- å¯ä»¥æ˜¯"å†è§"ã€"æ‹œæ‹œ"ã€"ä¸‹æœŸè§"ç­‰
- è¦è‡ªç„¶ã€æ¸©é¦¨
- æŒ‰é¡ºåºï¼š{' â†’ '.join(all_characters)}

## âš ï¸ è¾“å‡ºæ ¼å¼

{{
  "dialogues": [
    {{
      "character_name": "{all_characters[0]}",
      "content": "å†è§ï¼Œå„ä½å¬ä¼—æœ‹å‹ï¼",
      "emotion": "å¼€å¿ƒ"
    }}
  ]
}}

æ³¨æ„ï¼š
- ç›´æ¥è¾“å‡ºJSONï¼Œä¸è¦ç”¨```åŒ…è£¹
- ç”Ÿæˆ{len(all_characters)}æ®µé“åˆ«è¯­
- æ¯äººä¸€å¥ï¼Œç®€çŸ­æ¸©é¦¨

ç°åœ¨ç”Ÿæˆï¼š"""

        try:
            response = await self.deepseek_client.chat.completions.create(
                model=settings.deepseek_model,
                messages=[{"role": "user", "content": farewell_prompt}],
                temperature=0.6
            )

            result_text = response.choices[0].message.content.strip()

            # æ¸…ç†JSON
            if "```json" in result_text:
                result_text = result_text.split("```json")[1].split("```")[0].strip()
            elif "```" in result_text:
                result_text = result_text.split("```")[1].split("```")[0].strip()

            result_text = result_text.replace('\n', '\\n').replace('\r', '\\r').replace('\t', '\\t')
            result_text = re.sub(r'\\n\s*\\n', '\\n', result_text)

            try:
                farewell_data = json.loads(result_text)
            except json.JSONDecodeError:
                result_text_clean = re.sub(r'\\[nrt]', ' ', result_text)
                result_text_clean = re.sub(r'\s+', ' ', result_text_clean)
                farewell_data = json.loads(result_text_clean)

            # æ·»åŠ é›†ä½“é“åˆ«
            for dialogue_data in farewell_data["dialogues"]:
                original_content = dialogue_data["content"]
                cleaned_content = clean_for_tts(original_content, emotion=dialogue_data.get("emotion"))

                dialogue = ScriptDialogue(
                    character_name=dialogue_data["character_name"],
                    content=cleaned_content,
                    emotion=dialogue_data.get("emotion")
                )
                self.conversation_history.append(dialogue)

            print(f"[DEBUG] é›†ä½“é“åˆ«ç”Ÿæˆå®Œæˆ")

        except Exception as e:
            print(f"ç”Ÿæˆé›†ä½“é“åˆ«å¤±è´¥: {str(e)}")
            # æ·»åŠ é»˜è®¤é“åˆ«
            for character in all_characters:
                default_farewell = ScriptDialogue(
                    character_name=character,
                    content="å†è§ï¼",
                    emotion="å¼€å¿ƒ"
                )
                self.conversation_history.append(default_farewell)